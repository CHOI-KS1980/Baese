#!/usr/bin/env python3
"""
Gë¼ì´ë” HTML êµ¬ì¡° ë¶„ì„ ë„êµ¬
ì‹¤ì œ ë°ì´í„° íŒŒì‹± ë¡œì§ ê°œë°œì„ ìœ„í•´ HTML êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import requests
from bs4 import BeautifulSoup
import json
import re

def analyze_grider_html():
    """Gë¼ì´ë” ì‚¬ì´íŠ¸ HTML êµ¬ì¡° ë¶„ì„"""
    try:
        print("ğŸ”„ Gë¼ì´ë” ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘...")
        
        response = requests.get('https://jangboo.grider.ai/', 
                              headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'},
                              timeout=30)
        
        html_data = response.text
        print(f"âœ… HTML ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({len(html_data)} bytes)")
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        soup = BeautifulSoup(html_data, 'html.parser')
        
        print("\nğŸ“Š HTML êµ¬ì¡° ë¶„ì„:")
        print("=" * 60)
        
        # Title í™•ì¸
        title = soup.find('title')
        if title:
            print(f"ğŸ“Œ í˜ì´ì§€ ì œëª©: {title.get_text().strip()}")
        
        # ë¡œê·¸ì¸ ë¦¬ë‹¤ì´ë ‰íŠ¸ ì²´í¬
        if "<script>location.href='/login';</script>" in html_data:
            print("âš ï¸ ë¡œê·¸ì¸ í•„ìš” ìƒíƒœ")
            return
        
        # ì£¼ìš” ìš”ì†Œë“¤ ì°¾ê¸°
        print("\nğŸ” ì£¼ìš” ìš”ì†Œ ê²€ìƒ‰:")
        
        # ë¯¸ì…˜ ê´€ë ¨ í…ìŠ¤íŠ¸ ê²€ìƒ‰
        mission_keywords = ['ë¯¸ì…˜', 'ì•„ì¹¨', 'ì ì‹¬', 'ì €ë…', 'ì‹¬ì•¼', 'ë‹¬ì„±', 'ë¶€ì¡±']
        for keyword in mission_keywords:
            elements = soup.find_all(text=re.compile(keyword, re.IGNORECASE))
            if elements:
                print(f"  '{keyword}' ë°œê²¬: {len(elements)}ê°œ")
                for i, elem in enumerate(elements[:3]):  # ì²˜ìŒ 3ê°œë§Œ
                    print(f"    {i+1}. {elem.strip()[:50]}...")
        
        # ë¼ì´ë” ì´ë¦„ íŒ¨í„´ ê²€ìƒ‰
        print("\nğŸ‘¥ ë¼ì´ë” ê´€ë ¨ ì •ë³´:")
        rider_patterns = [r'[ê°€-í£]{2,4}', r'\d+ê±´', r'\d+\.?\d*%']
        for pattern in rider_patterns:
            matches = re.findall(pattern, html_data)
            if matches:
                print(f"  íŒ¨í„´ '{pattern}': {len(matches)}ê°œ ë°œê²¬")
                print(f"    ì˜ˆì‹œ: {matches[:5]}")
        
        # í…Œì´ë¸” êµ¬ì¡° í™•ì¸
        tables = soup.find_all('table')
        print(f"\nğŸ“‹ í…Œì´ë¸”: {len(tables)}ê°œ ë°œê²¬")
        for i, table in enumerate(tables):
            rows = table.find_all('tr')
            print(f"  í…Œì´ë¸” {i+1}: {len(rows)}í–‰")
            if rows:
                first_row = rows[0].get_text().strip()
                print(f"    ì²« ë²ˆì§¸ í–‰: {first_row[:50]}...")
        
        # DIV í´ë˜ìŠ¤ë“¤ í™•ì¸
        divs_with_class = soup.find_all('div', class_=True)
        print(f"\nğŸ“¦ í´ë˜ìŠ¤ê°€ ìˆëŠ” DIV: {len(divs_with_class)}ê°œ")
        class_names = set()
        for div in divs_with_class:
            classes = div.get('class', [])
            class_names.update(classes)
        
        print(f"  ê³ ìœ  í´ë˜ìŠ¤: {len(class_names)}ê°œ")
        for cls in sorted(list(class_names)[:10]):  # ì²˜ìŒ 10ê°œë§Œ
            print(f"    - {cls}")
        
        # ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ í™•ì¸
        scripts = soup.find_all('script')
        print(f"\nâš™ï¸ ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸: {len(scripts)}ê°œ")
        for i, script in enumerate(scripts):
            if script.string and len(script.string.strip()) > 20:
                content = script.string.strip()[:100]
                print(f"  ìŠ¤í¬ë¦½íŠ¸ {i+1}: {content}...")
        
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì íŒ¨í„´ ì°¾ê¸°
        print("\nğŸ”¢ ìˆ«ì íŒ¨í„´ ë¶„ì„:")
        number_patterns = {
            'í¼ì„¼íŠ¸': r'\d+\.?\d*%',
            'ê±´ìˆ˜': r'\d+ê±´',
            'ì ìˆ˜': r'\d+ì ',
            'ì‹œê°„': r'\d{1,2}:\d{2}',
            'ì˜¨ë„': r'\d+Â°C'
        }
        
        for name, pattern in number_patterns.items():
            matches = re.findall(pattern, html_data)
            if matches:
                print(f"  {name}: {matches[:5]}")
        
        # ì›ì‹œ HTML ì¼ë¶€ ì €ì¥ (ë””ë²„ê¹…ìš©)
        print(f"\nğŸ’¾ HTML ìƒ˜í”Œ ì €ì¥...")
        with open('grider_html_sample.txt', 'w', encoding='utf-8') as f:
            f.write(f"Gë¼ì´ë” HTML ë¶„ì„ ê²°ê³¼\n")
            f.write(f"{'='*50}\n\n")
            f.write(f"HTML ê¸¸ì´: {len(html_data)} bytes\n")
            f.write(f"Title: {title.get_text().strip() if title else 'None'}\n\n")
            f.write("HTML ì²˜ìŒ 2000ì:\n")
            f.write("-" * 30 + "\n")
            f.write(html_data[:2000])
            f.write("\n" + "-" * 30 + "\n\n")
            f.write("HTML ë§ˆì§€ë§‰ 1000ì:\n")
            f.write("-" * 30 + "\n")
            f.write(html_data[-1000:])
        
        print("âœ… ë¶„ì„ ì™„ë£Œ! 'grider_html_sample.txt' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    analyze_grider_html() 