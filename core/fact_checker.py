"""
ğŸ¤– ê³ ë„í™”ëœ AI íŒ©íŠ¸ ì²´ì»¤
ë‹¤ì¤‘ AI ëª¨ë¸ ì§€ì›, ì‹ ë¢°ë„ ì ìˆ˜, ê·¼ê±° ì¶”ì¶œ, ìë™ ê²€ì¦
"""

import asyncio
import json
import re
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
from auto_finance.utils.logger import setup_logger
from auto_finance.utils.error_handler import retry_on_error, ErrorHandler
from auto_finance.utils.cache_manager import cache_manager
from auto_finance.config.settings import AI_CONFIG, FACT_CHECK_CONFIG

logger = setup_logger(__name__)

@dataclass
class FactCheckResult:
    """íŒ©íŠ¸ ì²´í¬ ê²°ê³¼"""
    article_id: str
    title: str
    content: str
    fact_check_score: float
    confidence: float
    verification_status: str  # verified, disputed, uncertain
    evidence: List[str]
    reasoning: str
    ai_model: str
    checked_at: str
    processing_time: float

class FactChecker:
    """ê³ ë„í™”ëœ AI íŒ©íŠ¸ ì²´ì»¤"""
    
    def __init__(self):
        self.error_handler = ErrorHandler()
        self.ai_client = None
        self.model_name = AI_CONFIG.get('model_name', 'gemini-2.0-flash-exp')
        self.api_key = AI_CONFIG.get('api_key')
        
        # íŒ©íŠ¸ ì²´í¬ í†µê³„
        self.stats = {
            'total_checks': 0,
            'successful_checks': 0,
            'failed_checks': 0,
            'average_score': 0.0,
            'processing_time': 0.0
        }
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’
        self.confidence_threshold = FACT_CHECK_CONFIG.get('confidence_threshold', 0.7)
        self.score_threshold = FACT_CHECK_CONFIG.get('score_threshold', 0.6)
        
        logger.info(f"ğŸ¤– AI íŒ©íŠ¸ ì²´ì»¤ ì´ˆê¸°í™”: {self.model_name}")
    
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        await self.initialize()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.cleanup()
    
    async def initialize(self):
        """AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            if not self.api_key:
                logger.warning("âš ï¸ AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return
            
            # Google Gemini API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            
            # ëª¨ë¸ ì„¤ì •
            self.ai_client = genai.GenerativeModel(self.model_name)
            
            logger.info(f"âœ… AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name}")
            
        except Exception as e:
            logger.error(f"âŒ AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.ai_client:
                del self.ai_client
            
            logger.info("ğŸ§¹ AI íŒ©íŠ¸ ì²´ì»¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ AI íŒ©íŠ¸ ì²´ì»¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    @retry_on_error(max_retries=3, delay=2.0)
    async def check_fact(self, article: Dict[str, Any]) -> Optional[FactCheckResult]:
        """ë‹¨ì¼ ê¸°ì‚¬ íŒ©íŠ¸ ì²´í¬"""
        if not self.ai_client:
            logger.warning("âš ï¸ AI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        
        start_time = datetime.now()
        article_id = article.get('id', f"article_{hash(article['title'])}")
        
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"factcheck_{article_id}"
            cached_result = cache_manager.get(cache_key)
            
            if cached_result:
                logger.info(f"ğŸ’¾ ìºì‹œëœ íŒ©íŠ¸ ì²´í¬ ê²°ê³¼ ì‚¬ìš©: {article_id}")
                return FactCheckResult(**cached_result)
            
            # íŒ©íŠ¸ ì²´í¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_fact_check_prompt(article)
            
            # AI í˜¸ì¶œ
            response = await self._call_ai_api(prompt)
            
            # ì‘ë‹µ íŒŒì‹±
            result = self._parse_fact_check_response(response, article_id, article)
            
            if result:
                # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                processing_time = (datetime.now() - start_time).total_seconds()
                result.processing_time = processing_time
                
                # ìºì‹œ ì €ì¥
                cache_manager.set(cache_key, result.__dict__, ttl=3600)  # 1ì‹œê°„
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self._update_statistics(result)
                
                logger.info(f"âœ… íŒ©íŠ¸ ì²´í¬ ì™„ë£Œ: {article_id} (ì ìˆ˜: {result.fact_check_score:.2f})")
            
            return result
            
        except Exception as e:
            self.stats['failed_checks'] += 1
            self.error_handler.handle_error(e, f"íŒ©íŠ¸ ì²´í¬ ì‹¤íŒ¨ ({article_id})")
            logger.error(f"âŒ íŒ©íŠ¸ ì²´í¬ ì‹¤íŒ¨ ({article_id}): {e}")
            return None
    
    def _create_fact_check_prompt(self, article: Dict[str, Any]) -> str:
        """íŒ©íŠ¸ ì²´í¬ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        title = article.get('title', '')
        content = article.get('content', '')
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ ê²€ì¦í•´ì£¼ì„¸ìš”.

ì œëª©: {title}
ë‚´ìš©: {content}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”:

{{
    "fact_check_score": 0.0-1.0,  // ì‚¬ì‹¤ ì—¬ë¶€ ì ìˆ˜ (1.0ì´ ê°€ì¥ ì‚¬ì‹¤ì— ê°€ê¹Œì›€)
    "confidence": 0.0-1.0,        // ê²€ì¦ ì‹ ë¢°ë„ (1.0ì´ ê°€ì¥ í™•ì‹¤í•¨)
    "verification_status": "verified|disputed|uncertain",  // ê²€ì¦ ìƒíƒœ
    "evidence": [                 // ê·¼ê±° ëª©ë¡
        "ê·¼ê±° 1",
        "ê·¼ê±° 2"
    ],
    "reasoning": "ê²€ì¦ ê³¼ì •ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…"
}}

ì£¼ì˜ì‚¬í•­:
1. ê°ê´€ì ì´ê³  ì¤‘ë¦½ì ì¸ ê´€ì ì—ì„œ ê²€ì¦í•˜ì„¸ìš”
2. êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”
3. ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì‹ ë¢°ë„ë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì„¸ìš”
4. JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
"""
        
        return prompt
    
    async def _call_ai_api(self, prompt: str) -> str:
        """AI API í˜¸ì¶œ"""
        try:
            response = self.ai_client.generate_content(prompt)
            return response.text
            
        except Exception as e:
            logger.error(f"âŒ AI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _parse_fact_check_response(self, response: str, article_id: str, 
                                  article: Dict[str, Any]) -> Optional[FactCheckResult]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if not json_match:
                logger.error(f"âŒ JSON ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {response}")
                return None
            
            json_str = json_match.group()
            data = json.loads(json_str)
            
            # ê²°ê³¼ ê°ì²´ ìƒì„±
            result = FactCheckResult(
                article_id=article_id,
                title=article.get('title', ''),
                content=article.get('content', ''),
                fact_check_score=float(data.get('fact_check_score', 0.0)),
                confidence=float(data.get('confidence', 0.0)),
                verification_status=data.get('verification_status', 'uncertain'),
                evidence=data.get('evidence', []),
                reasoning=data.get('reasoning', ''),
                ai_model=self.model_name,
                checked_at=datetime.now().isoformat(),
                processing_time=0.0
            )
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
    
    def _update_statistics(self, result: FactCheckResult):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats['total_checks'] += 1
        self.stats['successful_checks'] += 1
        
        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        current_avg = self.stats['average_score']
        total_checks = self.stats['total_checks']
        self.stats['average_score'] = (current_avg * (total_checks - 1) + result.fact_check_score) / total_checks
    
    async def check_multiple_articles(self, articles: List[Dict[str, Any]], 
                                    max_concurrent: int = 5) -> List[FactCheckResult]:
        """ë‹¤ì¤‘ ê¸°ì‚¬ íŒ©íŠ¸ ì²´í¬"""
        if not articles:
            return []
        
        logger.info(f"ğŸ” ë‹¤ì¤‘ ê¸°ì‚¬ íŒ©íŠ¸ ì²´í¬ ì‹œì‘: {len(articles)}ê°œ ê¸°ì‚¬")
        
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì‹¤í–‰ ì œí•œ
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def check_with_semaphore(article):
            async with semaphore:
                return await self.check_fact(article)
        
        # ë³‘ë ¬ ì‹¤í–‰
        tasks = [check_with_semaphore(article) for article in articles]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ í•„í„°ë§
        valid_results = []
        for result in results:
            if isinstance(result, FactCheckResult):
                valid_results.append(result)
            elif isinstance(result, Exception):
                logger.error(f"âŒ íŒ©íŠ¸ ì²´í¬ ì‘ì—… ì‹¤íŒ¨: {result}")
        
        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        valid_results.sort(key=lambda x: x.confidence, reverse=True)
        
        logger.info(f"âœ… ë‹¤ì¤‘ íŒ©íŠ¸ ì²´í¬ ì™„ë£Œ: {len(valid_results)}ê°œ ì„±ê³µ")
        return valid_results
    
    def filter_high_confidence_results(self, results: List[FactCheckResult]) -> List[FactCheckResult]:
        """ë†’ì€ ì‹ ë¢°ë„ ê²°ê³¼ í•„í„°ë§"""
        return [r for r in results if r.confidence >= self.confidence_threshold]
    
    def filter_verified_results(self, results: List[FactCheckResult]) -> List[FactCheckResult]:
        """ê²€ì¦ëœ ê²°ê³¼ í•„í„°ë§"""
        return [r for r in results if r.verification_status == 'verified']
    
    def get_verification_summary(self, results: List[FactCheckResult]) -> Dict[str, Any]:
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½"""
        if not results:
            return {}
        
        summary = {
            'total_articles': len(results),
            'verified_count': len([r for r in results if r.verification_status == 'verified']),
            'disputed_count': len([r for r in results if r.verification_status == 'disputed']),
            'uncertain_count': len([r for r in results if r.verification_status == 'uncertain']),
            'average_score': sum(r.fact_check_score for r in results) / len(results),
            'average_confidence': sum(r.confidence for r in results) / len(results),
            'high_confidence_count': len([r for r in results if r.confidence >= self.confidence_threshold]),
            'timestamp': datetime.now().isoformat()
        }
        
        return summary
    
    def save_results(self, results: List[FactCheckResult], file_path: str = "data/fact_check_results.json"):
        """ê²°ê³¼ ì €ì¥"""
        try:
            # FactCheckResult ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            data = [result.__dict__ for result in results]
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ’¾ íŒ©íŠ¸ ì²´í¬ ê²°ê³¼ ì €ì¥: {file_path}")
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """íŒ©íŠ¸ ì²´í¬ í†µê³„ ë°˜í™˜"""
        return {
            **self.stats,
            'error_statistics': self.error_handler.get_statistics(),
            'model_name': self.model_name,
            'confidence_threshold': self.confidence_threshold,
            'score_threshold': self.score_threshold,
            'timestamp': datetime.now().isoformat()
        }

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """íŒ©íŠ¸ ì²´ì»¤ í…ŒìŠ¤íŠ¸"""
    test_articles = [
        {
            'id': 'test_1',
            'title': 'ì‚¼ì„±ì „ì 1ë¶„ê¸° ì‹¤ì  ì˜ˆìƒì¹˜ ìƒíšŒ',
            'content': 'ì‚¼ì„±ì „ìê°€ 1ë¶„ê¸° ì‹¤ì ì—ì„œ ì‹œì¥ ì˜ˆìƒì¹˜ë¥¼ ìƒíšŒí–ˆë‹¤ëŠ” ì†Œì‹ì´ ì „í•´ì¡ŒìŠµë‹ˆë‹¤.'
        },
        {
            'id': 'test_2', 
            'title': 'ì½”ë¡œë‚˜19 ë°±ì‹  ê°œë°œ ì™„ë£Œ',
            'content': 'ìƒˆë¡œìš´ ì½”ë¡œë‚˜19 ë°±ì‹ ì´ ê°œë°œë˜ì–´ ì„ìƒì‹œí—˜ì„ ì™„ë£Œí–ˆë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.'
        }
    ]
    
    async with FactChecker() as fact_checker:
        results = await fact_checker.check_multiple_articles(test_articles)
        
        print(f"ğŸ” íŒ©íŠ¸ ì²´í¬ ê²°ê³¼: {len(results)}ê°œ ê¸°ì‚¬")
        for result in results:
            print(f"- {result.title}")
            print(f"  ì ìˆ˜: {result.fact_check_score:.2f}, ì‹ ë¢°ë„: {result.confidence:.2f}")
            print(f"  ìƒíƒœ: {result.verification_status}")
            print()
        
        summary = fact_checker.get_verification_summary(results)
        print(f"ğŸ“Š ìš”ì•½: {summary}")

if __name__ == "__main__":
    asyncio.run(main()) 