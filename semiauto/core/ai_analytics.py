#!/usr/bin/env python3
"""
ğŸ¤– AI ê¸°ë°˜ ì§€ëŠ¥í˜• ë¶„ì„ ì‹œìŠ¤í…œ
- ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì„±ê³¼ ì˜ˆì¸¡
- ì‹¤ì‹œê°„ ì´ìƒ íŒ¨í„´ ê°ì§€
- ìë™ ìµœì í™” ì¶”ì²œ
- íŠ¸ë Œë“œ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import statistics
from dataclasses import dataclass
import pytz

logger = logging.getLogger(__name__)
KST = pytz.timezone('Asia/Seoul')

@dataclass
class PerformanceMetrics:
    """ì„±ê³¼ ì§€í‘œ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: datetime
    total_score: int
    total_completed: int
    mission_completion_rate: float
    avg_rider_efficiency: float
    peak_performance: Dict[str, float]
    anomaly_score: float

@dataclass
class PredictionResult:
    """ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    predicted_completion: int
    confidence: float
    trend: str  # 'increasing', 'decreasing', 'stable'
    recommendation: str
    risk_factors: List[str]

class AIAnalytics:
    """AI ê¸°ë°˜ ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.performance_history: List[PerformanceMetrics] = []
        self.analysis_cache = {}
        self.anomaly_threshold = 2.0  # í‘œì¤€í¸ì°¨ ê¸°ì¤€
        
        logger.info("ğŸ¤– AI ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def add_performance_data(self, data: Dict) -> None:
        """ì„±ê³¼ ë°ì´í„° ì¶”ê°€"""
        try:
            # ë¯¸ì…˜ ì™„ë£Œìœ¨ ê³„ì‚°
            total_missions = sum(mission.get('target', 0) for mission in data.get('missions', {}).values())
            total_completed = sum(mission.get('current', 0) for mission in data.get('missions', {}).values())
            completion_rate = (total_completed / total_missions * 100) if total_missions > 0 else 0
            
            # ë¼ì´ë” í‰ê·  íš¨ìœ¨ì„± ê³„ì‚°
            active_riders = [r for r in data.get('riders', []) if r.get('completed', 0) > 0]
            avg_efficiency = statistics.mean([r.get('acceptance_rate', 0) for r in active_riders]) if active_riders else 0
            
            # í”¼í¬ì‹œê°„ ì„±ê³¼ ë¶„ì„
            peak_performance = self._analyze_peak_performance(data)
            
            # ì´ìƒ ì ìˆ˜ ê³„ì‚°
            anomaly_score = self._calculate_anomaly_score(total_completed, completion_rate)
            
            metrics = PerformanceMetrics(
                timestamp=datetime.now(KST),
                total_score=data.get('total_score', 0),
                total_completed=total_completed,
                mission_completion_rate=completion_rate,
                avg_rider_efficiency=avg_efficiency,
                peak_performance=peak_performance,
                anomaly_score=anomaly_score
            )
            
            self.performance_history.append(metrics)
            
            # ìµœê·¼ 100ê°œ ë°ì´í„°ë§Œ ìœ ì§€
            if len(self.performance_history) > 100:
                self.performance_history = self.performance_history[-100:]
                
            logger.info(f"ğŸ“Š ì„±ê³¼ ë°ì´í„° ì¶”ê°€: ì™„ë£Œìœ¨ {completion_rate:.1f}%, ì´ìƒì ìˆ˜ {anomaly_score:.2f}")
            
        except Exception as e:
            logger.error(f"âŒ ì„±ê³¼ ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    def _analyze_peak_performance(self, data: Dict) -> Dict[str, float]:
        """í”¼í¬ì‹œê°„ë³„ ì„±ê³¼ ë¶„ì„"""
        missions = data.get('missions', {})
        peak_analysis = {}
        
        for mission_name, mission_data in missions.items():
            target = mission_data.get('target', 0)
            current = mission_data.get('current', 0)
            
            if target > 0:
                performance_ratio = current / target
                peak_analysis[mission_name] = performance_ratio
        
        return peak_analysis
    
    def _calculate_anomaly_score(self, current_completed: int, completion_rate: float) -> float:
        """ì´ìƒ ì ìˆ˜ ê³„ì‚°"""
        if len(self.performance_history) < 5:
            return 0.0
        
        # ìµœê·¼ ë°ì´í„° ê¸°ë°˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
        recent_completed = [m.total_completed for m in self.performance_history[-10:]]
        recent_rates = [m.mission_completion_rate for m in self.performance_history[-10:]]
        
        if len(recent_completed) < 2:
            return 0.0
        
        try:
            # Z-score ê³„ì‚°
            completed_mean = statistics.mean(recent_completed)
            completed_std = statistics.stdev(recent_completed)
            rate_mean = statistics.mean(recent_rates)
            rate_std = statistics.stdev(recent_rates)
            
            completed_z = abs((current_completed - completed_mean) / completed_std) if completed_std > 0 else 0
            rate_z = abs((completion_rate - rate_mean) / rate_std) if rate_std > 0 else 0
            
            return max(completed_z, rate_z)
            
        except Exception:
            return 0.0
    
    def predict_performance(self, target_time: datetime) -> PredictionResult:
        """ì„±ê³¼ ì˜ˆì¸¡"""
        try:
            if len(self.performance_history) < 3:
                return PredictionResult(
                    predicted_completion=0,
                    confidence=0.0,
                    trend='insufficient_data',
                    recommendation="ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                    risk_factors=['ë°ì´í„° ë¶€ì¡±']
                )
            
                        # ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„
            recent_data = self.performance_history[-5:]
            completed_values = [m.total_completed for m in recent_data]
            
            # ì„ í˜• íšŒê·€ë¥¼ í†µí•œ ì˜ˆì¸¡ (ê°„ë‹¨í•œ êµ¬í˜„)
            if len(completed_values) >= 2:
                trend_slope = self._calculate_trend([float(v) for v in completed_values])
                
                # ì˜ˆì¸¡ê°’ ê³„ì‚°
                base_value = completed_values[-1]
                hours_ahead = (target_time - recent_data[-1].timestamp).total_seconds() / 3600
                predicted = max(0, int(base_value + trend_slope * hours_ahead))
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                confidence = min(0.95, 0.5 + (len(self.performance_history) * 0.01))
                
                # íŠ¸ë Œë“œ ë¶„ë¥˜
                if trend_slope > 5:
                    trend = 'increasing'
                elif trend_slope < -5:
                    trend = 'decreasing'
                else:
                    trend = 'stable'
                
                # ì¶”ì²œì‚¬í•­ ìƒì„±
                recommendation = self._generate_recommendation(trend, recent_data[-1])
                
                # ìœ„í—˜ ìš”ì†Œ ë¶„ì„
                risk_factors = self._analyze_risk_factors(recent_data[-1])
                
                return PredictionResult(
                    predicted_completion=predicted,
                    confidence=confidence,
                    trend=trend,
                    recommendation=recommendation,
                    risk_factors=risk_factors
                )
            
        except Exception as e:
            logger.error(f"âŒ ì„±ê³¼ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        
        return PredictionResult(
            predicted_completion=0,
            confidence=0.0,
            trend='error',
            recommendation="ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì˜¤ë¥˜",
            risk_factors=['ì‹œìŠ¤í…œ ì˜¤ë¥˜']
        )
    
    def _calculate_trend(self, values: List[float]) -> float:
        """íŠ¸ë Œë“œ ê¸°ìš¸ê¸° ê³„ì‚°"""
        n = len(values)
        if n < 2:
            return 0
        
        x_values = list(range(n))
        x_mean = statistics.mean(x_values)
        y_mean = statistics.mean(values)
        
        numerator = sum((x - x_mean) * (y - y_mean) for x, y in zip(x_values, values))
        denominator = sum((x - x_mean) ** 2 for x in x_values)
        
        return numerator / denominator if denominator != 0 else 0
    
    def _generate_recommendation(self, trend: str, latest_metrics: PerformanceMetrics) -> str:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if trend == 'decreasing':
            recommendations.append("ğŸ“‰ ì„±ê³¼ í•˜ë½ ì¶”ì„¸ - ë¼ì´ë” ë™ê¸°ë¶€ì—¬ í•„ìš”")
        elif trend == 'increasing':
            recommendations.append("ğŸ“ˆ ì„±ê³¼ ìƒìŠ¹ ì¶”ì„¸ - í˜„ì¬ ì „ëµ ìœ ì§€")
        
        if latest_metrics.mission_completion_rate < 80:
            recommendations.append("âš ï¸ ë¯¸ì…˜ ì™„ë£Œìœ¨ ì €ì¡° - ëª©í‘œ ì¬ê²€í†  í•„ìš”")
        
        if latest_metrics.avg_rider_efficiency < 85:
            recommendations.append("ğŸ¯ ë¼ì´ë” íš¨ìœ¨ì„± ê°œì„  í•„ìš” - êµìœ¡ í”„ë¡œê·¸ë¨ ê²€í† ")
        
        if latest_metrics.anomaly_score > self.anomaly_threshold:
            recommendations.append("ğŸš¨ ì´ìƒ íŒ¨í„´ ê°ì§€ - ì¦‰ì‹œ ì ê²€ í•„ìš”")
        
        return " / ".join(recommendations) if recommendations else "âœ… ëª¨ë“  ì§€í‘œ ì–‘í˜¸"
    
    def _analyze_risk_factors(self, metrics: PerformanceMetrics) -> List[str]:
        """ìœ„í—˜ ìš”ì†Œ ë¶„ì„"""
        risks = []
        
        if metrics.anomaly_score > self.anomaly_threshold:
            risks.append("ì´ìƒ íŒ¨í„´ ê°ì§€")
        
        if metrics.mission_completion_rate < 70:
            risks.append("ë‚®ì€ ë¯¸ì…˜ ì™„ë£Œìœ¨")
        
        if metrics.avg_rider_efficiency < 80:
            risks.append("ë¼ì´ë” íš¨ìœ¨ì„± ì €í•˜")
        
        # í”¼í¬ì‹œê°„ ì„±ê³¼ ë¶„ì„
        poor_performance_peaks = [peak for peak, ratio in metrics.peak_performance.items() if ratio < 0.7]
        if poor_performance_peaks:
            risks.append(f"ì €ì¡°í•œ í”¼í¬ì‹œê°„: {', '.join(poor_performance_peaks)}")
        
        return risks if risks else ["ìœ„í—˜ ìš”ì†Œ ì—†ìŒ"]
    
    def get_intelligence_report(self) -> Dict:
        """ì§€ëŠ¥í˜• ë¶„ì„ ë¦¬í¬íŠ¸"""
        if not self.performance_history:
            return {"status": "ë°ì´í„° ë¶€ì¡±", "message": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        latest = self.performance_history[-1]
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction = self.predict_performance(datetime.now(KST) + timedelta(hours=1))
        
        # íŠ¸ë Œë“œ ë¶„ì„
        if len(self.performance_history) >= 5:
            recent_trend = self._analyze_recent_trend()
        else:
            recent_trend = "ë°ì´í„° ë¶€ì¡±"
        
        return {
            "timestamp": latest.timestamp.isoformat(),
            "current_performance": {
                "completion_rate": f"{latest.mission_completion_rate:.1f}%",
                "rider_efficiency": f"{latest.avg_rider_efficiency:.1f}%",
                "anomaly_score": f"{latest.anomaly_score:.2f}",
                "total_completed": latest.total_completed
            },
            "prediction": {
                "next_hour_completion": prediction.predicted_completion,
                "confidence": f"{prediction.confidence * 100:.1f}%",
                "trend": prediction.trend,
                "recommendation": prediction.recommendation
            },
            "risk_analysis": {
                "factors": prediction.risk_factors,
                "level": self._get_risk_level(latest.anomaly_score)
            },
            "trend_analysis": recent_trend
        }
    
    def _analyze_recent_trend(self) -> str:
        """ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„"""
        recent_data = self.performance_history[-5:]
        rates = [m.mission_completion_rate for m in recent_data]
        
        if len(rates) < 2:
            return "ë°ì´í„° ë¶€ì¡±"
        
        trend_slope = self._calculate_trend(rates)
        
        if trend_slope > 2:
            return "ğŸ“ˆ ì§€ì†ì  ê°œì„ "
        elif trend_slope < -2:
            return "ğŸ“‰ ì„±ê³¼ í•˜ë½"
        else:
            return "ğŸ“Š ì•ˆì •ì  ìœ ì§€"
    
    def _get_risk_level(self, anomaly_score: float) -> str:
        """ìœ„í—˜ ë ˆë²¨ í‰ê°€"""
        if anomaly_score > 3.0:
            return "ğŸ”´ ë†’ìŒ"
        elif anomaly_score > 2.0:
            return "ğŸŸ¡ ì¤‘ê°„"
        else:
            return "ğŸŸ¢ ë‚®ìŒ"
    
    def save_analytics_data(self, filepath: str = "analytics_data.json") -> None:
        """ë¶„ì„ ë°ì´í„° ì €ì¥"""
        try:
            data = {
                "performance_history": [
                    {
                        "timestamp": m.timestamp.isoformat(),
                        "total_score": m.total_score,
                        "total_completed": m.total_completed,
                        "mission_completion_rate": m.mission_completion_rate,
                        "avg_rider_efficiency": m.avg_rider_efficiency,
                        "peak_performance": m.peak_performance,
                        "anomaly_score": m.anomaly_score
                    }
                    for m in self.performance_history
                ]
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“Š ë¶„ì„ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_analytics_data(self, filepath: str = "analytics_data.json") -> None:
        """ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.performance_history = []
            for item in data.get("performance_history", []):
                metrics = PerformanceMetrics(
                    timestamp=datetime.fromisoformat(item["timestamp"]),
                    total_score=item["total_score"],
                    total_completed=item["total_completed"],
                    mission_completion_rate=item["mission_completion_rate"],
                    avg_rider_efficiency=item["avg_rider_efficiency"],
                    peak_performance=item["peak_performance"],
                    anomaly_score=item["anomaly_score"]
                )
                self.performance_history.append(metrics)
            
            logger.info(f"ğŸ“Š ë¶„ì„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.performance_history)}ê°œ í•­ëª©")
            
        except FileNotFoundError:
            logger.info("ğŸ“Š ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ì—†ìŒ - ìƒˆë¡œ ì‹œì‘")
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}") 