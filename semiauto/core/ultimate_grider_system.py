#!/usr/bin/env python3
"""
ğŸ¯ ìµœì¢… í†µí•© ê³ ë„í™” ì‹œìŠ¤í…œ
- AI ë¶„ì„ + ë‹¤ì¤‘ í”Œë«í¼ + ìµœì í™” ì—”ì§„ í†µí•©
- ì°¨ì„¸ëŒ€ ìë™í™” ì‹œìŠ¤í…œ
- ì‹¤ì‹œê°„ ì§€ëŠ¥í˜• ëª¨ë‹ˆí„°ë§
- ì˜ˆì¸¡ ê¸°ë°˜ ì‚¬ì „ ëŒ€ì‘
"""

import sys
import os
import logging
import time
import psutil
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pytz

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from core.enhanced_final_solution import EnhancedGriderAutoSender
from core.ai_analytics import AIAnalytics
from core.final_solution import KakaoSender
# from core.multi_platform_notifier import MultiPlatformNotifier
# from core.optimization_engine import OptimizationEngine

logger = logging.getLogger(__name__)
KST = pytz.timezone('Asia/Seoul')

class UltimateGriderSystem(EnhancedGriderAutoSender):
    """ì°¨ì„¸ëŒ€ Gë¼ì´ë” ìë™í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, rest_api_key, refresh_token):
        super().__init__(rest_api_key, refresh_token)
        
        # ê³ ë„í™” ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.ai_analytics = AIAnalytics()
        # self.multi_notifier = MultiPlatformNotifier()
        # self.optimization_engine = OptimizationEngine()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.system_start_time = datetime.now(KST)
        self.total_executions = 0
        self.successful_executions = 0
        self.ai_predictions_made = 0
        self.optimizations_applied = 0
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.execution_times = []
        self.last_optimization = None
        
        logger.info("ğŸš€ ì°¨ì„¸ëŒ€ Gë¼ì´ë” ìë™í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        self._log_system_capabilities()
    
    def _log_system_capabilities(self):
        """ì‹œìŠ¤í…œ ê¸°ëŠ¥ ë¡œê¹…"""
        capabilities = [
            "âœ… AI ê¸°ë°˜ ì„±ê³¼ ì˜ˆì¸¡ ë° ì´ìƒ íŒ¨í„´ ê°ì§€",
            "âœ… ì‹¤ì‹œê°„ ë°ì´í„° ê²€ì¦ ë° ìë™ ìˆ˜ì •",
            "âœ… ì •í™•í•œ ì‹œê°„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§",
            "âœ… ì¤‘ë³µ ë°©ì§€ ë° ëˆ„ë½ ë©”ì‹œì§€ ë³µêµ¬",
            "âœ… ì§€ëŠ¥í˜• ë¶„ì„ ë¦¬í¬íŠ¸",
            # "âœ… ë‹¤ì¤‘ í”Œë«í¼ ì•Œë¦¼ (ìŠ¬ë™, ë””ìŠ¤ì½”ë“œ, í…”ë ˆê·¸ë¨, ì´ë©”ì¼)",
            # "âœ… ë™ì  ì„±ëŠ¥ ìµœì í™”",
            "âœ… ì¢…í•© ìƒíƒœ ëª¨ë‹ˆí„°ë§"
        ]
        
        logger.info("ğŸ¯ ì‹œìŠ¤í…œ ê¸°ëŠ¥:")
        for capability in capabilities:
            logger.info(f"   {capability}")
    
    def execute_intelligent_automation(self) -> Dict:
        """ì§€ëŠ¥í˜• ìë™í™” ì‹¤í–‰"""
        start_time = time.time()
        execution_result = {
            "timestamp": datetime.now(KST).isoformat(),
            "success": False,
            "execution_time": 0.0,
            "ai_analysis": {},
            "data_quality": 0.0,
            "notifications_sent": {},
            "optimizations": [],
            "errors": []
        }
        
        try:
            logger.info("ğŸš€ ì§€ëŠ¥í˜• ìë™í™” ì‹œì‘...")
            
            # 1. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì²´í¬
            system_resources = self._check_system_resources()
            logger.info(f"ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤: CPU {system_resources['cpu']}%, ë©”ëª¨ë¦¬ {system_resources['memory']}%")
            
            # 2. ìŠ¤ì¼€ì¤„ ê²€ì¦ ë° ë°ì´í„° ìˆ˜ì§‘
            should_send, reason = self.scheduler.should_send_now()
            if not should_send:
                logger.info(f"â¸ï¸ ì „ì†¡ ìŠ¤í‚µ: {reason}")
                if "ìš´ì˜ì‹œê°„ ì™¸" in reason:
                    execution_result["success"] = True
                    execution_result["reason"] = reason
                return execution_result
            
            # 3. ë°ì´í„° ìˆ˜ì§‘ ë° ê²€ì¦
            logger.info("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
            data = self.data_collector.get_grider_data()
            
            if not data:
                execution_result["errors"].append("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                return execution_result
            
            # 4. AI ë¶„ì„ ì¶”ê°€
            logger.info("ğŸ¤– AI ë¶„ì„ ì‹œì‘...")
            self.ai_analytics.add_performance_data(data)
            ai_report = self.ai_analytics.get_intelligence_report()
            execution_result["ai_analysis"] = ai_report
            self.ai_predictions_made += 1
            
            # 5. ë°ì´í„° ê²€ì¦
            logger.info("ğŸ” ë°ì´í„° ê²€ì¦ ì¤‘...")
            is_valid, validation_result = self.data_validator.validate_data(data, "crawler")
            execution_result["data_quality"] = validation_result.get("quality_score", 0.0)
            
            if not is_valid:
                logger.warning("âš ï¸ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨, ìë™ ìˆ˜ì • ì‹œë„...")
                data = self.data_validator.fix_data_issues(data, validation_result)
                
                # ì¬ê²€ì¦
                is_valid, _ = self.data_validator.validate_data(data, "auto_fixed")
                if not is_valid:
                    execution_result["errors"].append("ë°ì´í„° ìë™ ìˆ˜ì • ì‹¤íŒ¨")
                    return execution_result
            
            # 6. ê¸°ë³¸ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ ì „ì†¡
            access_token = self.token_manager.get_valid_token()
            self.sender = KakaoSender(access_token)
            
            message = self.format_message(data)
            result = self.sender.send_text_message(message)
            
            if result.get('result_code') == 0:
                # ì „ì†¡ ì„±ê³µ ê¸°ë¡
                target_time = datetime.now(KST).replace(second=0, microsecond=0)
                message_id = str(result.get('result_id', f"msg_{int(datetime.now().timestamp())}"))
                data_hash = self.data_validator.freshness_checker.get_data_hash(data)
                
                self.scheduler.history.record_sent(target_time, message_id, data_hash)
                
                logger.info("âœ… ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ!")
                execution_result["success"] = True
            else:
                execution_result["errors"].append(f"ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ ì‹¤íŒ¨: {result}")
                
            # 7. ë‹¤ì¤‘ í”Œë«í¼ ì•Œë¦¼ (ì£¼ì„ ì²˜ë¦¬)
            # if self.multi_notifier.platforms:
            #     logger.info("ğŸ“¤ ë‹¤ì¤‘ í”Œë«í¼ ì•Œë¦¼ ì „ì†¡...")
            #     notification_results = self.multi_notifier.send_grider_report(data)
            #     execution_result["notifications_sent"] = notification_results
            
            # 8. AI ì˜ˆì¸¡ ê¸°ë°˜ ì•Œë¦¼
            if ai_report.get("risk_analysis", {}).get("level") == "ğŸ”´ ë†’ìŒ":
                logger.warning("ğŸš¨ AIê°€ ë†’ì€ ìœ„í—˜ë„ë¥¼ ê°ì§€í–ˆìŠµë‹ˆë‹¤!")
                # self.multi_notifier.send_alert(
                #     f"âš ï¸ AI ìœ„í—˜ ê°ì§€: {ai_report['prediction']['recommendation']}",
                #     "ğŸš¨ Gë¼ì´ë” ì‹œìŠ¤í…œ ì£¼ì˜ ì•Œë¦¼",
                #     "high"
                # )
            
        except Exception as e:
            logger.error(f"âŒ ì§€ëŠ¥í˜• ìë™í™” ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            execution_result["errors"].append(str(e))
        
        finally:
            # ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
            execution_time = time.time() - start_time
            execution_result["execution_time"] = execution_time
            self.execution_times.append(execution_time)
            
            # ìµœê·¼ 50ê°œ ì‹¤í–‰ì‹œê°„ë§Œ ìœ ì§€
            if len(self.execution_times) > 50:
                self.execution_times = self.execution_times[-50:]
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.total_executions += 1
            if execution_result["success"]:
                self.successful_executions += 1
            
            # ì„±ëŠ¥ ìµœì í™” ì—”ì§„ì— ë°ì´í„° ì œê³µ (ì£¼ì„ ì²˜ë¦¬)
            # success_rate = (self.successful_executions / self.total_executions * 100) if self.total_executions > 0 else 0
            # self.optimization_engine.performance_monitor.record_metrics(
            #     execution_time=execution_time,
            #     success_rate=success_rate,
            #     data_quality=execution_result["data_quality"],
            #     system_load=system_resources["cpu"] / 100,
            #     memory_usage=system_resources["memory_mb"],
            #     network_latency=0.0  # ì¶”í›„ êµ¬í˜„
            # )
            
            logger.info(f"â±ï¸ ì‹¤í–‰ ì™„ë£Œ: {execution_time:.2f}ì´ˆ")
        
        return execution_result
    
    def _check_system_resources(self) -> Dict:
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì²´í¬"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_mb = memory.used / 1024 / 1024
            
            return {
                "cpu": cpu_percent,
                "memory": memory_percent,
                "memory_mb": memory_mb,
                "available_gb": memory.available / 1024 / 1024 / 1024
            }
        except Exception as e:
            logger.warning(f"âš ï¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
            return {"cpu": 0, "memory": 0, "memory_mb": 0, "available_gb": 0}
    
    def run_optimization_cycle(self) -> Dict:
        """ìµœì í™” ì‚¬ì´í´ ì‹¤í–‰"""
        logger.info("ğŸ”§ ìµœì í™” ì‚¬ì´í´ ì‹œì‘...")
        
        optimization_result = {
            "timestamp": datetime.now(KST).isoformat(),
            "performed": False,
            "recommendations": [],
            "improvements_applied": []
        }
        
        # ì£¼ì„ ì²˜ë¦¬: ìµœì í™” ì—”ì§„ ì‚¬ìš©
        # try:
        #     # ìµœì í™” ë¶„ì„ ì‹¤í–‰
        #     analysis = self.optimization_engine.analyze_and_optimize()
        #     
        #     if analysis.get("status") == "complete":
        #         recommendations = analysis.get("recommendations", [])
        #         optimization_result["recommendations"] = recommendations
        #         
        #         # ìë™ ì ìš© ê°€ëŠ¥í•œ ìµœì í™” ì‹¤í–‰
        #         for rec in recommendations:
        #             if rec.get("implementation_effort") == "easy" and rec.get("priority") in ["high", "medium"]:
        #                 # ì—¬ê¸°ì„œ ì‹¤ì œ ìµœì í™” ì ìš©
        #                 optimization_result["improvements_applied"].append(rec["description"])
        #                 self.optimizations_applied += 1
        #         
        #         self.last_optimization = datetime.now(KST)
        #         optimization_result["performed"] = True
        #         
        #         logger.info(f"ğŸ”§ ìµœì í™” ì™„ë£Œ: {len(recommendations)}ê°œ ê¶Œì¥ì‚¬í•­, {len(optimization_result['improvements_applied'])}ê°œ ì ìš©")
        #     
        # except Exception as e:
        #     logger.error(f"âŒ ìµœì í™” ì‚¬ì´í´ ì‹¤íŒ¨: {e}")
        #     optimization_result["error"] = str(e)
        
        return optimization_result
    
    def get_comprehensive_status(self) -> Dict:
        """ì¢…í•© ìƒíƒœ ë¦¬í¬íŠ¸"""
        uptime = datetime.now(KST) - self.system_start_time
        success_rate = (self.successful_executions / self.total_executions * 100) if self.total_executions > 0 else 0
        avg_execution_time = sum(self.execution_times) / len(self.execution_times) if self.execution_times else 0
        
        # AI ë¶„ì„ í†µê³„
        ai_report = self.ai_analytics.get_intelligence_report() if self.ai_analytics.performance_history else {}
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ
        scheduler_status = self.scheduler.get_status_report()
        
        # ê²€ì¦ í†µê³„
        validation_stats = self.data_validator.get_validation_stats()
        
        # ìµœì í™” ìš”ì•½ (ì£¼ì„ ì²˜ë¦¬)
        # optimization_summary = self.optimization_engine.get_optimization_summary()
        
        return {
            "ğŸ¯ ì‹œìŠ¤í…œ ì •ë³´": {
                "ì‹œì‘ ì‹œê°„": self.system_start_time.strftime('%Y-%m-%d %H:%M:%S'),
                "ìš´ì˜ ì‹œê°„": f"{uptime.days}ì¼ {uptime.seconds//3600}ì‹œê°„ {(uptime.seconds%3600)//60}ë¶„",
                "ë²„ì „": "Ultimate v2.0"
            },
            "ğŸ“Š ì‹¤í–‰ í†µê³„": {
                "ì´ ì‹¤í–‰": self.total_executions,
                "ì„±ê³µ ì‹¤í–‰": self.successful_executions,
                "ì„±ê³µë¥ ": f"{success_rate:.1f}%",
                "í‰ê·  ì‹¤í–‰ì‹œê°„": f"{avg_execution_time:.2f}ì´ˆ"
            },
            "ğŸ¤– AI ë¶„ì„": {
                "ì˜ˆì¸¡ ìˆ˜í–‰": self.ai_predictions_made,
                "ìµœê·¼ ë¶„ì„": ai_report.get("timestamp", "ì—†ìŒ"),
                "í˜„ì¬ íŠ¸ë Œë“œ": ai_report.get("trend_analysis", "ë°ì´í„° ë¶€ì¡±"),
                "ìœ„í—˜ ìˆ˜ì¤€": ai_report.get("risk_analysis", {}).get("level", "ğŸŸ¢ ë‚®ìŒ")
            },
            "ğŸ“… ìŠ¤ì¼€ì¤„ë§": scheduler_status,
            "ğŸ” ë°ì´í„° ê²€ì¦": {
                "ì´ ê²€ì¦": validation_stats.get('total', 0),
                "ì„±ê³µ": validation_stats.get('valid', 0),
                "ì‹¤íŒ¨": validation_stats.get('invalid', 0),
                "ì„±ê³µë¥ ": f"{validation_stats.get('success_rate', 0):.1f}%"
            },
            # "ğŸ”§ ìµœì í™”": {
            #     "ì ìš©ëœ ìµœì í™”": self.optimizations_applied,
            #     "ë§ˆì§€ë§‰ ìµœì í™”": self.last_optimization.strftime('%Y-%m-%d %H:%M:%S') if self.last_optimization else "ì—†ìŒ",
            #     "ì‹œìŠ¤í…œ ìƒíƒœ": optimization_summary.get("system_health", "ğŸŸ¢ ì–‘í˜¸")
            # },
            "ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤": self._check_system_resources()
        }
    
    def run_single_ultimate_execution(self) -> bool:
        """ë‹¨ì¼ ìµœê³ ê¸‰ ì‹¤í–‰ (GitHub Actionsìš©)"""
        logger.info("ğŸŒŸ ì°¨ì„¸ëŒ€ Gë¼ì´ë” ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹œì‘!")
        
        try:
            # 1. ëˆ„ë½ëœ ë©”ì‹œì§€ ë³µêµ¬
            logger.info("ğŸ”„ ëˆ„ë½ ë©”ì‹œì§€ ë³µêµ¬ ì¤‘...")
            recovered_count = self.scheduler.recover_missing_messages()
            if recovered_count and recovered_count > 0:
                logger.info(f"âœ… {recovered_count}ê°œ ë©”ì‹œì§€ ë³µêµ¬ ì™„ë£Œ")
            
            # 2. ì§€ëŠ¥í˜• ìë™í™” ì‹¤í–‰
            execution_result = self.execute_intelligent_automation()
            
            # 3. ìµœì í™” ì‚¬ì´í´ (ì£¼ê¸°ì ìœ¼ë¡œ)
            # if self.total_executions % 10 == 0:  # 10ë²ˆ ì‹¤í–‰ë§ˆë‹¤
            #     optimization_result = self.run_optimization_cycle()
            #     logger.info(f"ğŸ”§ ìµœì í™” ê²°ê³¼: {optimization_result}")
            
            # 4. ì¢…í•© ìƒíƒœ ë¦¬í¬íŠ¸
            status = self.get_comprehensive_status()
            logger.info("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬í¬íŠ¸:")
            for category, details in status.items():
                logger.info(f"  {category}:")
                if isinstance(details, dict):
                    for key, value in details.items():
                        logger.info(f"    â€¢ {key}: {value}")
                else:
                    logger.info(f"    {details}")
            
            # 5. AI ì¸ì‚¬ì´íŠ¸ ì¶œë ¥
            if execution_result.get("ai_analysis"):
                ai_analysis = execution_result["ai_analysis"]
                if ai_analysis.get("prediction"):
                    pred = ai_analysis["prediction"]
                    logger.info(f"ğŸ¤– AI ì˜ˆì¸¡: {pred.get('trend', 'N/A')} íŠ¸ë Œë“œ, ì‹ ë¢°ë„ {pred.get('confidence', 'N/A')}")
                    logger.info(f"ğŸ¯ AI ê¶Œì¥ì‚¬í•­: {pred.get('recommendation', 'N/A')}")
            
            # 6. ì„±ê³µ/ì‹¤íŒ¨ íŒì •
            success = execution_result.get("success", False)
            
            if success:
                logger.info("ğŸ‰ ì°¨ì„¸ëŒ€ Gë¼ì´ë” ì‹œìŠ¤í…œ ì‹¤í–‰ ì„±ê³µ!")
            else:
                errors = execution_result.get("errors", [])
                logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {', '.join(errors)}")
            
            return success
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ì°¨ì„¸ëŒ€ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            return False
    
    def start_ultimate_scheduler(self):
        """ì°¨ì„¸ëŒ€ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        logger.info("ğŸŒŸ ì°¨ì„¸ëŒ€ Gë¼ì´ë” ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘!")
        logger.info("ğŸš€ AI ë¶„ì„, ì§€ëŠ¥í˜• ìµœì í™”, ë‹¤ì¤‘ í”Œë«í¼ ì•Œë¦¼ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì‹œì‘ ìƒíƒœ ì¶œë ¥
        status = self.get_comprehensive_status()
        logger.info("ğŸ“Š ì‹œìŠ¤í…œ ì´ˆê¸° ìƒíƒœ:")
        for category, details in status.items():
            logger.info(f"  {category}: {details}")
        
        try:
            while True:
                now = datetime.now(KST)
                
                # ìš´ì˜ì‹œê°„ ì²´í¬ (10:00~23:59)
                if 10 <= now.hour <= 23:
                    # ì •í™•í•œ ë¶„ì— ì‹¤í–‰
                    expected_minutes = self.scheduler.validator.get_expected_minutes(now)
                    
                    if now.minute in expected_minutes and now.second < 30:
                        # ì§€ëŠ¥í˜• ìë™í™” ì‹¤í–‰
                        execution_result = self.execute_intelligent_automation()
                        
                        if execution_result.get("success"):
                            logger.info(f"ğŸŒŸ ì§€ëŠ¥í˜• ì „ì†¡ ì™„ë£Œ: {now.strftime('%H:%M')}")
                        
                        # ì „ì†¡ í›„ 60ì´ˆ ëŒ€ê¸° (ì¤‘ë³µ ë°©ì§€)
                        time.sleep(60)
                    
                    # 10ë¶„ë§ˆë‹¤ ëˆ„ë½ ë©”ì‹œì§€ ì²´í¬
                    elif now.minute % 10 == 0 and now.second < 30:
                        self.scheduler.recover_missing_messages()
                        time.sleep(60)
                    
                    # 1ì‹œê°„ë§ˆë‹¤ ìµœì í™” ìˆ˜í–‰ (ì£¼ì„ ì²˜ë¦¬)
                    # elif now.minute == 0 and now.second < 30:
                    #     self.run_optimization_cycle()
                    #     time.sleep(60)
                
                # 30ì´ˆë§ˆë‹¤ ì²´í¬
                time.sleep(30)
                
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ì§€ë¨")
            self._save_system_data()
        except Exception as e:
            logger.error(f"ğŸ’¥ ì°¨ì„¸ëŒ€ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {e}")
            self._save_system_data()
    
    def _save_system_data(self):
        """ì‹œìŠ¤í…œ ë°ì´í„° ì €ì¥"""
        try:
            # AI ë¶„ì„ ë°ì´í„° ì €ì¥
            self.ai_analytics.save_analytics_data("ai_analytics_data.json")
            
            # ìµœì í™” ë°ì´í„° ì €ì¥ (ì£¼ì„ ì²˜ë¦¬)
            # self.optimization_engine.save_optimization_data("optimization_data.json")
            
            logger.info("ğŸ’¾ ì‹œìŠ¤í…œ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì°¨ì„¸ëŒ€ Gë¼ì´ë” ìë™í™” ì‹œìŠ¤í…œ')
    parser.add_argument('--mode', choices=['normal', 'single', 'status'], 
                       default='single', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--config', default='../config.txt', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('ultimate_grider.log', encoding='utf-8')
        ]
    )
    
    try:
        # í™˜ê²½ë³€ìˆ˜ ìš°ì„  ì²´í¬
        import os
        rest_api_key = os.getenv('REST_API_KEY')
        refresh_token = os.getenv('REFRESH_TOKEN')
        
        # ë””ë²„ê·¸: í™˜ê²½ë³€ìˆ˜ ìƒíƒœ ë¡œê¹…
        logger.info(f"ğŸ” REST_API_KEY í™˜ê²½ë³€ìˆ˜ ì¡´ì¬: {'ìˆìŒ' if rest_api_key else 'ì—†ìŒ'}")
        logger.info(f"ğŸ” REFRESH_TOKEN í™˜ê²½ë³€ìˆ˜ ì¡´ì¬: {'ìˆìŒ' if refresh_token else 'ì—†ìŒ'}")
        
        if rest_api_key and refresh_token:
            logger.info("âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ REST_API_KEY, REFRESH_TOKEN ë¡œë“œ ì™„ë£Œ")
        else:
            logger.error("âŒ REST_API_KEY ë˜ëŠ” REFRESH_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            logger.error("ğŸ’¡ GitHub Actionsì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤")
            
            # ì¶”ê°€ ë””ë²„ê·¸: ëª¨ë“  í™˜ê²½ë³€ìˆ˜ ì¶œë ¥
            env_vars = dict(os.environ)
            logger.error(f"ğŸ” í˜„ì¬ í™˜ê²½ë³€ìˆ˜ ê°œìˆ˜: {len(env_vars)}")
            rest_keys = [k for k in env_vars.keys() if 'REST' in k.upper()]
            refresh_keys = [k for k in env_vars.keys() if 'REFRESH' in k.upper() or 'TOKEN' in k.upper()]
            logger.error(f"ğŸ” REST ê´€ë ¨ í™˜ê²½ë³€ìˆ˜: {rest_keys}")
            logger.error(f"ğŸ” TOKEN ê´€ë ¨ í™˜ê²½ë³€ìˆ˜: {refresh_keys}")
            
            sys.exit(1)
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        system = UltimateGriderSystem(
            rest_api_key=rest_api_key,
            refresh_token=refresh_token
        )
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        system.ai_analytics.load_analytics_data("ai_analytics_data.json")
        # system.optimization_engine.load_optimization_data("optimization_data.json")
        
        if args.mode == 'single':
            # ë‹¨ì¼ ì‹¤í–‰
            success = system.run_single_ultimate_execution()
            sys.exit(0 if success else 1)
            
        elif args.mode == 'normal':
            # ì§€ì†ì  ì‹¤í–‰
            system.start_ultimate_scheduler()
            
        elif args.mode == 'status':
            # ìƒíƒœ í™•ì¸ë§Œ
            status = system.get_comprehensive_status()
            print("ğŸŒŸ ì°¨ì„¸ëŒ€ Gë¼ì´ë” ì‹œìŠ¤í…œ ìƒíƒœ:")
            for category, details in status.items():
                print(f"\n{category}:")
                if isinstance(details, dict):
                    for key, value in details.items():
                        print(f"  â€¢ {key}: {value}")
                else:
                    print(f"  {details}")
    
    except Exception as e:
        logger.error(f"ğŸ’¥ ì‹œìŠ¤í…œ ì‹œì‘ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 