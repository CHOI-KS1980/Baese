#!/usr/bin/env python3
"""
ğŸ”§ ê³ ê¸‰ ìë™í™” ìµœì í™” ì—”ì§„
- ë™ì  ìŠ¤ì¼€ì¤„ ìµœì í™”
- ì„±ëŠ¥ ê¸°ë°˜ ìë™ ì¡°ì •
- ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ìµœì í™”
- ì˜ˆì¸¡ ê¸°ë°˜ ì‚¬ì „ ëŒ€ì‘
"""

import json
import logging
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import pytz

logger = logging.getLogger(__name__)
KST = pytz.timezone('Asia/Seoul')

@dataclass
class OptimizationMetrics:
    """ìµœì í™” ì§€í‘œ"""
    timestamp: datetime
    execution_time: float  # ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
    success_rate: float   # ì„±ê³µë¥  (%)
    data_quality: float   # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜
    system_load: float    # ì‹œìŠ¤í…œ ë¶€í•˜
    memory_usage: float   # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
    network_latency: float # ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì‹œê°„ (ms)

@dataclass
class OptimizationRecommendation:
    """ìµœì í™” ê¶Œì¥ì‚¬í•­"""
    category: str         # 'schedule', 'performance', 'resource'
    priority: str         # 'high', 'medium', 'low'
    description: str      # ê¶Œì¥ì‚¬í•­ ì„¤ëª…
    expected_improvement: float  # ì˜ˆìƒ ê°œì„ ìœ¨ (%)
    implementation_effort: str   # 'easy', 'medium', 'hard'

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.metrics_history: List[OptimizationMetrics] = []
        self.baseline_metrics: Optional[OptimizationMetrics] = None
        
    def record_metrics(self, execution_time: float, success_rate: float, 
                      data_quality: float, system_load: float = 0.0,
                      memory_usage: float = 0.0, network_latency: float = 0.0):
        """ì„±ëŠ¥ ì§€í‘œ ê¸°ë¡"""
        metrics = OptimizationMetrics(
            timestamp=datetime.now(KST),
            execution_time=execution_time,
            success_rate=success_rate,
            data_quality=data_quality,
            system_load=system_load,
            memory_usage=memory_usage,
            network_latency=network_latency
        )
        
        self.metrics_history.append(metrics)
        
        # ìµœê·¼ 100ê°œ ë°ì´í„°ë§Œ ìœ ì§€
        if len(self.metrics_history) > 100:
            self.metrics_history = self.metrics_history[-100:]
        
        # ë² ì´ìŠ¤ë¼ì¸ ì„¤ì • (ì²« ë²ˆì§¸ ë°ì´í„°)
        if self.baseline_metrics is None:
            self.baseline_metrics = metrics
            
        logger.info(f"ğŸ“Š ì„±ëŠ¥ ì§€í‘œ ê¸°ë¡: ì‹¤í–‰ì‹œê°„ {execution_time:.2f}s, ì„±ê³µë¥  {success_rate:.1f}%")
    
    def get_performance_trend(self, metric_name: str, days: int = 7) -> Dict:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        cutoff_time = datetime.now(KST) - timedelta(days=days)
        recent_metrics = [m for m in self.metrics_history if m.timestamp >= cutoff_time]
        
        if len(recent_metrics) < 2:
            return {"trend": "insufficient_data", "change": 0.0}
        
        values = [getattr(m, metric_name) for m in recent_metrics]
        
        # ì„ í˜• íšŒê·€ë¥¼ í†µí•œ íŠ¸ë Œë“œ ê³„ì‚°
        n = len(values)
        x_values = list(range(n))
        x_mean = statistics.mean(x_values)
        y_mean = statistics.mean(values)
        
        numerator = sum((x - x_mean) * (y - y_mean) for x, y in zip(x_values, values))
        denominator = sum((x - x_mean) ** 2 for x in x_values)
        
        if denominator == 0:
            slope = 0
        else:
            slope = numerator / denominator
        
        # ë³€í™”ìœ¨ ê³„ì‚°
        if len(values) >= 2:
            change_rate = ((values[-1] - values[0]) / values[0] * 100) if values[0] != 0 else 0
        else:
            change_rate = 0
        
        trend = "improving" if slope > 0 else "declining" if slope < 0 else "stable"
        
        return {
            "trend": trend,
            "change": change_rate,
            "slope": slope,
            "current_value": values[-1],
            "average": statistics.mean(values)
        }

class ScheduleOptimizer:
    """ìŠ¤ì¼€ì¤„ ìµœì í™”ê¸°"""
    
    def __init__(self):
        self.schedule_performance: Dict[str, List[float]] = {}
        self.optimal_intervals: Dict[str, int] = {
            "peak_hours": 15,      # í”¼í¬ì‹œê°„ ê¸°ë³¸ ê°„ê²© (ë¶„)
            "normal_hours": 30,    # ì¼ë°˜ì‹œê°„ ê¸°ë³¸ ê°„ê²© (ë¶„)
            "low_hours": 60        # ì €ë¶€í•˜ì‹œê°„ ê¸°ë³¸ ê°„ê²© (ë¶„)
        }
    
    def analyze_optimal_timing(self, performance_history: List[OptimizationMetrics]) -> Dict:
        """ìµœì  íƒ€ì´ë° ë¶„ì„"""
        if len(performance_history) < 10:
            return {"status": "insufficient_data"}
        
        # ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥ ë¶„ì„
        hourly_performance = {}
        for metrics in performance_history:
            hour = metrics.timestamp.hour
            if hour not in hourly_performance:
                hourly_performance[hour] = []
            
            # ì„±ê³µë¥ ê³¼ ì‹¤í–‰ì‹œê°„ì„ ê²°í•©í•œ ì„±ëŠ¥ ì ìˆ˜
            performance_score = metrics.success_rate - (metrics.execution_time * 10)
            hourly_performance[hour].append(performance_score)
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        hourly_averages = {
            hour: statistics.mean(scores) 
            for hour, scores in hourly_performance.items()
        }
        
        # ìµœì /ìµœì•… ì‹œê°„ëŒ€ ì°¾ê¸°
        best_hours = sorted(hourly_averages.items(), key=lambda x: x[1], reverse=True)[:3]
        worst_hours = sorted(hourly_averages.items(), key=lambda x: x[1])[:3]
        
        return {
            "best_hours": [hour for hour, _ in best_hours],
            "worst_hours": [hour for hour, _ in worst_hours],
            "hourly_performance": hourly_averages,
            "recommendation": self._generate_schedule_recommendation(hourly_averages)
        }
    
    def _generate_schedule_recommendation(self, hourly_performance: Dict[int, float]) -> str:
        """ìŠ¤ì¼€ì¤„ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        if not hourly_performance:
            return "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        best_hour = max(hourly_performance.items(), key=lambda x: x[1])[0]
        worst_hour = min(hourly_performance.items(), key=lambda x: x[1])[0]
        
        recommendations = []
        
        # í”¼í¬ì‹œê°„ ì¡°ì •
        peak_hours = [11, 12, 17, 18, 19, 20, 21]
        peak_performance = [hourly_performance.get(h, 0) for h in peak_hours]
        avg_peak_performance = statistics.mean(peak_performance) if peak_performance else 0
        
        if avg_peak_performance < 50:
            recommendations.append("í”¼í¬ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°„ê²©ì„ 30ë¶„ìœ¼ë¡œ ëŠ˜ë ¤ ì‹œìŠ¤í…œ ë¶€í•˜ ê°ì†Œ")
        elif avg_peak_performance > 80:
            recommendations.append("í”¼í¬ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°„ê²©ì„ 10ë¶„ìœ¼ë¡œ ì¤„ì—¬ ì‹¤ì‹œê°„ì„± í–¥ìƒ")
        
        # ì €ì„±ëŠ¥ ì‹œê°„ëŒ€ ì¡°ì •
        if hourly_performance[worst_hour] < 30:
            recommendations.append(f"{worst_hour}ì‹œ ì„±ëŠ¥ì´ ì €ì¡°í•˜ë¯€ë¡œ í•´ë‹¹ ì‹œê°„ëŒ€ ëª¨ë‹ˆí„°ë§ ê°•í™” í•„ìš”")
        
        return " / ".join(recommendations) if recommendations else "í˜„ì¬ ìŠ¤ì¼€ì¤„ì´ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    
    def optimize_intervals(self, current_performance: float, time_category: str) -> int:
        """ê°„ê²© ìµœì í™”"""
        current_interval = self.optimal_intervals.get(time_category, 30)
        
        # ì„±ëŠ¥ ê¸°ë°˜ ë™ì  ì¡°ì •
        if current_performance < 50:  # ì„±ëŠ¥ ì €ì¡°
            new_interval = min(current_interval + 5, 60)  # ê°„ê²© ëŠ˜ë¦¬ê¸°
        elif current_performance > 90:  # ì„±ëŠ¥ ìš°ìˆ˜
            new_interval = max(current_interval - 5, 10)  # ê°„ê²© ì¤„ì´ê¸°
        else:
            new_interval = current_interval  # ìœ ì§€
        
        self.optimal_intervals[time_category] = new_interval
        return new_interval

class ResourceOptimizer:
    """ë¦¬ì†ŒìŠ¤ ìµœì í™”ê¸°"""
    
    def __init__(self):
        self.resource_thresholds = {
            "memory_warning": 500,    # MB
            "memory_critical": 1000,  # MB
            "latency_warning": 5000,  # ms
            "latency_critical": 10000 # ms
        }
    
    def analyze_resource_usage(self, metrics_history: List[OptimizationMetrics]) -> Dict:
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„"""
        if not metrics_history:
            return {"status": "no_data"}
        
        recent_metrics = metrics_history[-20:]  # ìµœê·¼ 20ê°œ ë°ì´í„°
        
        # í‰ê·  ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ê³„ì‚°
        avg_memory = statistics.mean([m.memory_usage for m in recent_metrics])
        avg_latency = statistics.mean([m.network_latency for m in recent_metrics])
        avg_load = statistics.mean([m.system_load for m in recent_metrics])
        
        # í”¼í¬ ì‚¬ìš©ëŸ‰
        peak_memory = max([m.memory_usage for m in recent_metrics])
        peak_latency = max([m.network_latency for m in recent_metrics])
        
        # ë¦¬ì†ŒìŠ¤ ìƒíƒœ í‰ê°€
        memory_status = self._evaluate_resource_status(avg_memory, "memory")
        latency_status = self._evaluate_resource_status(avg_latency, "latency")
        
        return {
            "memory": {
                "average": avg_memory,
                "peak": peak_memory,
                "status": memory_status,
                "threshold": self.resource_thresholds["memory_warning"]
            },
            "network": {
                "average_latency": avg_latency,
                "peak_latency": peak_latency,
                "status": latency_status,
                "threshold": self.resource_thresholds["latency_warning"]
            },
            "system_load": {
                "average": avg_load,
                "status": "normal" if avg_load < 0.8 else "high"
            }
        }
    
    def _evaluate_resource_status(self, value: float, resource_type: str) -> str:
        """ë¦¬ì†ŒìŠ¤ ìƒíƒœ í‰ê°€"""
        if resource_type == "memory":
            if value > self.resource_thresholds["memory_critical"]:
                return "critical"
            elif value > self.resource_thresholds["memory_warning"]:
                return "warning"
            else:
                return "normal"
        elif resource_type == "latency":
            if value > self.resource_thresholds["latency_critical"]:
                return "critical"
            elif value > self.resource_thresholds["latency_warning"]:
                return "warning"
            else:
                return "normal"
        
        return "unknown"
    
    def generate_optimization_recommendations(self, resource_analysis: Dict) -> List[OptimizationRecommendation]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        memory_status = resource_analysis.get("memory", {}).get("status", "normal")
        if memory_status == "critical":
            recommendations.append(OptimizationRecommendation(
                category="resource",
                priority="high",
                description="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ì¹˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ìºì‹œ í¬ê¸° ì¶•ì†Œ ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™” í•„ìš”",
                expected_improvement=30.0,
                implementation_effort="medium"
            ))
        elif memory_status == "warning":
            recommendations.append(OptimizationRecommendation(
                category="resource",
                priority="medium",
                description="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê°•í™” ë° ë¶ˆí•„ìš”í•œ ë°ì´í„° ì •ë¦¬",
                expected_improvement=15.0,
                implementation_effort="easy"
            ))
        
        # ë„¤íŠ¸ì›Œí¬ ìµœì í™”
        latency_status = resource_analysis.get("network", {}).get("status", "normal")
        if latency_status == "critical":
            recommendations.append(OptimizationRecommendation(
                category="performance",
                priority="high",
                description="ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì‹œê°„ì´ ê³¼ë„í•©ë‹ˆë‹¤. íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¡°ì • ë° ì¬ì‹œë„ ë¡œì§ ìµœì í™”",
                expected_improvement=25.0,
                implementation_effort="medium"
            ))
        
        # ì‹œìŠ¤í…œ ë¶€í•˜ ìµœì í™”
        load_status = resource_analysis.get("system_load", {}).get("status", "normal")
        if load_status == "high":
            recommendations.append(OptimizationRecommendation(
                category="schedule",
                priority="medium",
                description="ì‹œìŠ¤í…œ ë¶€í•˜ê°€ ë†’ìŠµë‹ˆë‹¤. ì‹¤í–‰ ê°„ê²© ì¡°ì • ë° ë™ì‹œ ì‹¤í–‰ ì œí•œ ê³ ë ¤",
                expected_improvement=20.0,
                implementation_effort="easy"
            ))
        
        return recommendations

class OptimizationEngine:
    """í†µí•© ìµœì í™” ì—”ì§„"""
    
    def __init__(self):
        self.performance_monitor = PerformanceMonitor()
        self.schedule_optimizer = ScheduleOptimizer()
        self.resource_optimizer = ResourceOptimizer()
        
        self.optimization_history: List[Dict] = []
        
        logger.info("ğŸ”§ ìµœì í™” ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def analyze_and_optimize(self) -> Dict:
        """ì¢…í•© ë¶„ì„ ë° ìµœì í™”"""
        try:
            if len(self.performance_monitor.metrics_history) < 5:
                return {
                    "status": "insufficient_data",
                    "message": "ìµœì í™”ë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "recommendations": []
                }
            
            # ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
            trends = {}
            for metric in ['execution_time', 'success_rate', 'data_quality']:
                trends[metric] = self.performance_monitor.get_performance_trend(metric)
            
            # ìŠ¤ì¼€ì¤„ ìµœì í™” ë¶„ì„
            schedule_analysis = self.schedule_optimizer.analyze_optimal_timing(
                self.performance_monitor.metrics_history
            )
            
            # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„
            resource_analysis = self.resource_optimizer.analyze_resource_usage(
                self.performance_monitor.metrics_history
            )
            
            # ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self.resource_optimizer.generate_optimization_recommendations(
                resource_analysis
            )
            
            # ìŠ¤ì¼€ì¤„ ê¶Œì¥ì‚¬í•­ ì¶”ê°€
            if schedule_analysis.get("recommendation"):
                recommendations.append(OptimizationRecommendation(
                    category="schedule",
                    priority="medium",
                    description=schedule_analysis["recommendation"],
                    expected_improvement=10.0,
                    implementation_effort="easy"
                ))
            
            # ì„±ëŠ¥ ì €í•˜ ê°ì§€ ë° ê¶Œì¥ì‚¬í•­
            success_trend = trends.get('success_rate', {})
            if success_trend.get('trend') == 'declining' and success_trend.get('change', 0) < -10:
                recommendations.append(OptimizationRecommendation(
                    category="performance",
                    priority="high",
                    description="ì„±ê³µë¥ ì´ ì§€ì†ì ìœ¼ë¡œ í•˜ë½í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë¡œê·¸ ì ê²€ ë° ì‹œìŠ¤í…œ ì•ˆì •ì„± ê°•í™” í•„ìš”",
                    expected_improvement=15.0,
                    implementation_effort="medium"
                ))
            
            optimization_result = {
                "timestamp": datetime.now(KST).isoformat(),
                "status": "complete",
                "performance_trends": trends,
                "schedule_analysis": schedule_analysis,
                "resource_analysis": resource_analysis,
                "recommendations": [asdict(rec) for rec in recommendations],
                "total_recommendations": len(recommendations),
                "high_priority_count": len([r for r in recommendations if r.priority == "high"])
            }
            
            # ìµœì í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.optimization_history.append(optimization_result)
            
            # ìµœê·¼ 50ê°œ ë¶„ì„ë§Œ ìœ ì§€
            if len(self.optimization_history) > 50:
                self.optimization_history = self.optimization_history[-50:]
            
            logger.info(f"ğŸ”§ ìµœì í™” ë¶„ì„ ì™„ë£Œ: {len(recommendations)}ê°œ ê¶Œì¥ì‚¬í•­ ìƒì„±")
            
            return optimization_result
            
        except Exception as e:
            logger.error(f"âŒ ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "message": f"ìµœì í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}",
                "recommendations": []
            }
    
    def get_optimization_summary(self) -> Dict:
        """ìµœì í™” ìš”ì•½ ì •ë³´"""
        if not self.optimization_history:
            return {"status": "no_data"}
        
        latest = self.optimization_history[-1]
        
        # ìµœê·¼ ê¶Œì¥ì‚¬í•­ í†µê³„
        recent_recommendations = []
        for analysis in self.optimization_history[-5:]:  # ìµœê·¼ 5ê°œ ë¶„ì„
            recent_recommendations.extend(analysis.get("recommendations", []))
        
        category_counts = {}
        priority_counts = {}
        
        for rec in recent_recommendations:
            category = rec.get("category", "unknown")
            priority = rec.get("priority", "unknown")
            
            category_counts[category] = category_counts.get(category, 0) + 1
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
        
        return {
            "last_analysis": latest.get("timestamp"),
            "total_analyses": len(self.optimization_history),
            "latest_recommendations": len(latest.get("recommendations", [])),
            "category_distribution": category_counts,
            "priority_distribution": priority_counts,
            "performance_trends": latest.get("performance_trends", {}),
            "system_health": self._assess_system_health(latest)
        }
    
    def _assess_system_health(self, latest_analysis: Dict) -> str:
        """ì‹œìŠ¤í…œ ìƒíƒœ í‰ê°€"""
        high_priority_count = latest_analysis.get("high_priority_count", 0)
        
        # ì„±ëŠ¥ íŠ¸ë Œë“œ í™•ì¸
        trends = latest_analysis.get("performance_trends", {})
        success_trend = trends.get("success_rate", {}).get("trend", "stable")
        
        if high_priority_count > 3:
            return "ğŸ”´ ì£¼ì˜ í•„ìš”"
        elif high_priority_count > 0 or success_trend == "declining":
            return "ğŸŸ¡ ëª¨ë‹ˆí„°ë§ ê°•í™”"
        else:
            return "ğŸŸ¢ ì–‘í˜¸"
    
    def save_optimization_data(self, filepath: str = "optimization_data.json"):
        """ìµœì í™” ë°ì´í„° ì €ì¥"""
        try:
            data = {
                "optimization_history": self.optimization_history,
                "performance_metrics": [
                    {
                        "timestamp": m.timestamp.isoformat(),
                        "execution_time": m.execution_time,
                        "success_rate": m.success_rate,
                        "data_quality": m.data_quality,
                        "system_load": m.system_load,
                        "memory_usage": m.memory_usage,
                        "network_latency": m.network_latency
                    }
                    for m in self.performance_monitor.metrics_history
                ]
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ”§ ìµœì í™” ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ ìµœì í™” ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_optimization_data(self, filepath: str = "optimization_data.json"):
        """ìµœì í™” ë°ì´í„° ë¡œë“œ"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ìµœì í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ
            self.optimization_history = data.get("optimization_history", [])
            
            # ì„±ëŠ¥ ì§€í‘œ íˆìŠ¤í† ë¦¬ ë¡œë“œ
            metrics_data = data.get("performance_metrics", [])
            self.performance_monitor.metrics_history = []
            
            for item in metrics_data:
                metrics = OptimizationMetrics(
                    timestamp=datetime.fromisoformat(item["timestamp"]),
                    execution_time=item["execution_time"],
                    success_rate=item["success_rate"],
                    data_quality=item["data_quality"],
                    system_load=item["system_load"],
                    memory_usage=item["memory_usage"],
                    network_latency=item["network_latency"]
                )
                self.performance_monitor.metrics_history.append(metrics)
            
            logger.info(f"ğŸ”§ ìµœì í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.optimization_history)}ê°œ ë¶„ì„, {len(metrics_data)}ê°œ ì§€í‘œ")
            
        except FileNotFoundError:
            logger.info("ğŸ”§ ê¸°ì¡´ ìµœì í™” ë°ì´í„° ì—†ìŒ - ìƒˆë¡œ ì‹œì‘")
        except Exception as e:
            logger.error(f"âŒ ìµœì í™” ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}") 