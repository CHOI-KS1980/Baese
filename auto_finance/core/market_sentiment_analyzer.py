"""
ğŸ“Š ì‹œì¥ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ
ë‹¤ì¤‘ ê¸°ë²•ì„ í™œìš©í•œ ê³ ë„í™”ëœ ì‹œì¥ ê°ì • ë¶„ì„
"""

import asyncio
import json
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
from textblob import TextBlob
import yfinance as yf
import requests
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

from auto_finance.utils.logger import setup_logger
from auto_finance.config.settings import FINANCIAL_CONFIG

logger = setup_logger(__name__)

@dataclass
class SentimentScore:
    """ê°ì • ì ìˆ˜ ë°ì´í„° í´ë˜ìŠ¤"""
    positive: float
    negative: float
    neutral: float
    compound: float
    confidence: float
    source: str
    timestamp: datetime

@dataclass
class MarketSentiment:
    """ì‹œì¥ ê°ì • ë°ì´í„° í´ë˜ìŠ¤"""
    overall_sentiment: float
    sentiment_trend: str
    confidence_score: float
    sources_analyzed: int
    sentiment_scores: List[SentimentScore]
    market_indicators: Dict[str, Any]
    timestamp: datetime

@dataclass
class NewsSentiment:
    """ë‰´ìŠ¤ ê°ì • ë°ì´í„° í´ë˜ìŠ¤"""
    article_id: str
    title_sentiment: SentimentScore
    content_sentiment: SentimentScore
    overall_sentiment: SentimentScore
    keywords: List[str]
    impact_score: float
    timestamp: datetime

class MarketSentimentAnalyzer:
    """ì‹œì¥ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.vader_analyzer = SentimentIntensityAnalyzer()
        
        # í•œêµ­ì–´ ê°ì • ì‚¬ì „ í™•ì¥
        self.korean_sentiment_words = {
            'positive': [
                'ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'ì„±ì¥', 'ì‹¤ì ', 'ìˆ˜ìµ', 'ì´ìµ', 'ì¦ê°€', 'ê°œì„ ', 'íšŒë³µ',
                'ê°•ì„¸', 'ëŒíŒŒ', 'ìƒí–¥', 'ê¸ì •', 'ë‚™ê´€', 'ê¸°ëŒ€', 'í¬ë§', 'ì„±ê³µ', 'ëŒíŒŒ', 'ì‹ ê¸°ë¡'
            ],
            'negative': [
                'í•˜ë½', 'ê¸‰ë½', 'ì•…ì¬', 'ì†ì‹¤', 'ê°ì†Œ', 'ì•…í™”', 'ìœ„í—˜', 'ìš°ë ¤', 'ë¶ˆì•ˆ', 'ê³µí¬',
                'ì•½ì„¸', 'í•˜í–¥', 'ë¶€ì •', 'ë¹„ê´€', 'ì‹¤ë§', 'ì‹¤íŒ¨', 'ìœ„ê¸°', 'í­ë½', 'ì¹¨ì²´', 'íŒŒì‚°'
            ]
        }
        
        # ê°ì • ë¶„ì„ ê°€ì¤‘ì¹˜
        self.sentiment_weights = {
            'vader': 0.3,
            'textblob': 0.2,
            'custom_korean': 0.3,
            'market_indicators': 0.2
        }
        
        self.stats = {
            'total_analyses': 0,
            'successful_analyses': 0,
            'failed_analyses': 0,
            'average_processing_time': 0.0,
            'sentiment_trends': {
                'positive': 0,
                'neutral': 0,
                'negative': 0
            }
        }
    
    async def analyze_news_sentiment(self, articles: List[Dict[str, Any]]) -> List[NewsSentiment]:
        """ë‰´ìŠ¤ ê¸°ì‚¬ ê°ì • ë¶„ì„"""
        logger.info(f"ğŸ“Š ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹œì‘: {len(articles)}ê°œ ê¸°ì‚¬")
        
        results = []
        start_time = time.time()
        
        try:
            for article in articles:
                try:
                    sentiment = await self._analyze_single_article(article)
                    results.append(sentiment)
                    self.stats['successful_analyses'] += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ê¸°ì‚¬ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
                    self.stats['failed_analyses'] += 1
                    continue
            
            processing_time = time.time() - start_time
            self.stats['total_analyses'] += len(articles)
            self.stats['average_processing_time'] = processing_time / len(articles) if articles else 0
            
            logger.info(f"âœ… ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì„±ê³µ, {processing_time:.2f}ì´ˆ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []
    
    async def _analyze_single_article(self, article: Dict[str, Any]) -> NewsSentiment:
        """ë‹¨ì¼ ê¸°ì‚¬ ê°ì • ë¶„ì„"""
        article_id = article.get('id', str(hash(article.get('title', ''))))
        title = article.get('title', '')
        content = article.get('content', '')
        
        # ì œëª© ê°ì • ë¶„ì„
        title_sentiment = await self._analyze_text_sentiment(title)
        
        # ë³¸ë¬¸ ê°ì • ë¶„ì„
        content_sentiment = await self._analyze_text_sentiment(content)
        
        # ì „ì²´ ê°ì • ì ìˆ˜ ê³„ì‚°
        overall_sentiment = self._calculate_overall_sentiment(title_sentiment, content_sentiment)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(title + ' ' + content)
        
        # ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚°
        impact_score = self._calculate_impact_score(article, overall_sentiment)
        
        return NewsSentiment(
            article_id=article_id,
            title_sentiment=title_sentiment,
            content_sentiment=content_sentiment,
            overall_sentiment=overall_sentiment,
            keywords=keywords,
            impact_score=impact_score,
            timestamp=datetime.now()
        )
    
    async def _analyze_text_sentiment(self, text: str) -> SentimentScore:
        """í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        if not text or len(text.strip()) < 10:
            return SentimentScore(0.0, 0.0, 1.0, 0.0, 0.0, 'empty_text', datetime.now())
        
        # VADER ê°ì • ë¶„ì„
        vader_scores = self.vader_analyzer.polarity_scores(text)
        
        # TextBlob ê°ì • ë¶„ì„
        blob = TextBlob(text)
        textblob_sentiment = blob.sentiment.polarity
        
        # í•œêµ­ì–´ ì»¤ìŠ¤í…€ ê°ì • ë¶„ì„
        korean_sentiment = self._analyze_korean_sentiment(text)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        compound_score = (
            vader_scores['compound'] * self.sentiment_weights['vader'] +
            textblob_sentiment * self.sentiment_weights['textblob'] +
            korean_sentiment * self.sentiment_weights['custom_korean']
        )
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_sentiment_confidence(text, vader_scores, textblob_sentiment)
        
        return SentimentScore(
            positive=vader_scores['pos'],
            negative=vader_scores['neg'],
            neutral=vader_scores['neu'],
            compound=compound_score,
            confidence=confidence,
            source='ensemble',
            timestamp=datetime.now()
        )
    
    def _analyze_korean_sentiment(self, text: str) -> float:
        """í•œêµ­ì–´ ì»¤ìŠ¤í…€ ê°ì • ë¶„ì„"""
        positive_count = 0
        negative_count = 0
        
        for word in self.korean_sentiment_words['positive']:
            if word in text:
                positive_count += 1
        
        for word in self.korean_sentiment_words['negative']:
            if word in text:
                negative_count += 1
        
        total_words = len(text.split())
        if total_words == 0:
            return 0.0
        
        # ê°ì • ì ìˆ˜ ê³„ì‚°
        sentiment_score = (positive_count - negative_count) / total_words
        
        # -1ì—ì„œ 1 ì‚¬ì´ë¡œ ì •ê·œí™”
        return max(-1.0, min(1.0, sentiment_score * 10))
    
    def _calculate_sentiment_confidence(self, text: str, vader_scores: Dict, textblob_sentiment: float) -> float:
        """ê°ì • ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì‹ ë¢°ë„
        length_confidence = min(len(text) / 100, 1.0)
        
        # VADER ì‹ ë¢°ë„
        vader_confidence = abs(vader_scores['compound'])
        
        # TextBlob ì‹ ë¢°ë„
        textblob_confidence = abs(textblob_sentiment)
        
        # í‰ê·  ì‹ ë¢°ë„
        avg_confidence = (length_confidence + vader_confidence + textblob_confidence) / 3
        
        return min(avg_confidence, 1.0)
    
    def _calculate_overall_sentiment(self, title_sentiment: SentimentScore, content_sentiment: SentimentScore) -> SentimentScore:
        """ì „ì²´ ê°ì • ì ìˆ˜ ê³„ì‚° (ì œëª© ê°€ì¤‘ì¹˜ 40%, ë³¸ë¬¸ 60%)"""
        title_weight = 0.4
        content_weight = 0.6
        
        compound = (title_sentiment.compound * title_weight + 
                   content_sentiment.compound * content_weight)
        
        positive = (title_sentiment.positive * title_weight + 
                   content_sentiment.positive * content_weight)
        
        negative = (title_sentiment.negative * title_weight + 
                   content_sentiment.negative * content_weight)
        
        neutral = (title_sentiment.neutral * title_weight + 
                  content_sentiment.neutral * content_weight)
        
        confidence = (title_sentiment.confidence * title_weight + 
                     content_sentiment.confidence * content_weight)
        
        return SentimentScore(
            positive=positive,
            negative=negative,
            neutral=neutral,
            compound=compound,
            confidence=confidence,
            source='weighted_ensemble',
            timestamp=datetime.now()
        )
    
    def _extract_keywords(self, text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš©)
        keywords = []
        
        # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
        financial_keywords = [
            'ì£¼ì‹', 'íˆ¬ì', 'ê²½ì œ', 'ê¸ˆìœµ', 'ì‹œì¥', 'ë¶„ì„', 'ì „ë§', 'ì „ëµ',
            'í¬íŠ¸í´ë¦¬ì˜¤', 'ë¦¬ìŠ¤í¬', 'ìˆ˜ìµë¥ ', 'ì„±ì¥', 'ê°€ì¹˜', 'ë°°ë‹¹',
            'ìƒìŠ¹', 'í•˜ë½', 'ê¸‰ë“±', 'ê¸‰ë½', 'í˜¸ì¬', 'ì•…ì¬'
        ]
        
        for keyword in financial_keywords:
            if keyword in text:
                keywords.append(keyword)
        
        return keywords[:10]  # ìµœëŒ€ 10ê°œ
    
    def _calculate_impact_score(self, article: Dict[str, Any], sentiment: SentimentScore) -> float:
        """ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚°"""
        impact_score = 0.0
        
        # ê°ì • ê°•ë„
        impact_score += abs(sentiment.compound) * 0.3
        
        # ê¸°ì‚¬ ê¸¸ì´
        content_length = len(article.get('content', ''))
        if content_length > 500:
            impact_score += 0.2
        elif content_length > 200:
            impact_score += 0.1
        
        # ì†ŒìŠ¤ ì‹ ë¢°ë„
        source = article.get('source', '').lower()
        if 'ë„¤ì´ë²„' in source or 'í•œêµ­ê²½ì œ' in source:
            impact_score += 0.2
        elif 'ë§¤ì¼ê²½ì œ' in source or 'ì´ë°ì¼ë¦¬' in source:
            impact_score += 0.15
        
        # í‚¤ì›Œë“œ ì¤‘ìš”ë„
        keywords = self._extract_keywords(article.get('title', '') + ' ' + article.get('content', ''))
        important_keywords = ['ê¸‰ë“±', 'ê¸‰ë½', 'í˜¸ì¬', 'ì•…ì¬', 'ëŒíŒŒ', 'í­ë½']
        for keyword in important_keywords:
            if keyword in keywords:
                impact_score += 0.1
        
        return min(impact_score, 1.0)
    
    async def analyze_market_sentiment(self, news_sentiments: List[NewsSentiment]) -> MarketSentiment:
        """ì „ì²´ ì‹œì¥ ê°ì • ë¶„ì„"""
        logger.info("ğŸ“ˆ ì „ì²´ ì‹œì¥ ê°ì • ë¶„ì„ ì‹œì‘")
        
        try:
            if not news_sentiments:
                return self._create_empty_market_sentiment()
            
            # ë‰´ìŠ¤ ê°ì • ì§‘ê³„
            overall_sentiment = self._aggregate_news_sentiments(news_sentiments)
            
            # ì‹œì¥ ì§€í‘œ ìˆ˜ì§‘
            market_indicators = await self._collect_market_indicators()
            
            # ê°ì • íŠ¸ë Œë“œ ë¶„ì„
            sentiment_trend = self._analyze_sentiment_trend(news_sentiments)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence_score = self._calculate_market_confidence(news_sentiments, market_indicators)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_sentiment_trends(overall_sentiment)
            
            market_sentiment = MarketSentiment(
                overall_sentiment=overall_sentiment,
                sentiment_trend=sentiment_trend,
                confidence_score=confidence_score,
                sources_analyzed=len(news_sentiments),
                sentiment_scores=[ns.overall_sentiment for ns in news_sentiments],
                market_indicators=market_indicators,
                timestamp=datetime.now()
            )
            
            logger.info(f"âœ… ì‹œì¥ ê°ì • ë¶„ì„ ì™„ë£Œ: {overall_sentiment:.3f} ({sentiment_trend})")
            return market_sentiment
            
        except Exception as e:
            logger.error(f"âŒ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_empty_market_sentiment()
    
    def _aggregate_news_sentiments(self, news_sentiments: List[NewsSentiment]) -> float:
        """ë‰´ìŠ¤ ê°ì • ì§‘ê³„"""
        if not news_sentiments:
            return 0.0
        
        # ì˜í–¥ë„ ê°€ì¤‘ í‰ê· 
        total_weight = 0
        weighted_sum = 0
        
        for sentiment in news_sentiments:
            weight = sentiment.impact_score
            total_weight += weight
            weighted_sum += sentiment.overall_sentiment.compound * weight
        
        return weighted_sum / total_weight if total_weight > 0 else 0.0
    
    async def _collect_market_indicators(self) -> Dict[str, Any]:
        """ì‹œì¥ ì§€í‘œ ìˆ˜ì§‘"""
        indicators = {}
        
        try:
            # ì£¼ìš” ì§€ìˆ˜ ë°ì´í„°
            indices = ['^KS11', '^KQ11', '^GSPC', '^DJI', '^IXIC']
            
            for index in indices:
                try:
                    ticker = yf.Ticker(index)
                    hist = ticker.history(period='5d')
                    
                    if not hist.empty:
                        current_price = hist['Close'].iloc[-1]
                        prev_price = hist['Close'].iloc[-2]
                        change_pct = ((current_price - prev_price) / prev_price) * 100
                        
                        indicators[index] = {
                            'current_price': current_price,
                            'change_pct': change_pct,
                            'trend': 'up' if change_pct > 0 else 'down' if change_pct < 0 else 'flat'
                        }
                        
                except Exception as e:
                    logger.warning(f"ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ {index}: {e}")
                    continue
            
            # VIX ì§€ìˆ˜ (ë³€ë™ì„±)
            try:
                vix = yf.Ticker('^VIX')
                vix_hist = vix.history(period='5d')
                if not vix_hist.empty:
                    indicators['vix'] = {
                        'current_value': vix_hist['Close'].iloc[-1],
                        'trend': 'high' if vix_hist['Close'].iloc[-1] > 20 else 'low'
                    }
            except Exception as e:
                logger.warning(f"VIX ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ì§€í‘œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return indicators
    
    def _analyze_sentiment_trend(self, news_sentiments: List[NewsSentiment]) -> str:
        """ê°ì • íŠ¸ë Œë“œ ë¶„ì„"""
        if not news_sentiments:
            return 'neutral'
        
        # ìµœê·¼ ê¸°ì‚¬ë“¤ì˜ ê°ì • ë¶„ì„
        recent_sentiments = news_sentiments[-10:]  # ìµœê·¼ 10ê°œ
        
        positive_count = 0
        negative_count = 0
        
        for sentiment in recent_sentiments:
            if sentiment.overall_sentiment.compound > 0.1:
                positive_count += 1
            elif sentiment.overall_sentiment.compound < -0.1:
                negative_count += 1
        
        if positive_count > negative_count * 1.5:
            return 'strongly_positive'
        elif positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count * 1.5:
            return 'strongly_negative'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'
    
    def _calculate_market_confidence(self, news_sentiments: List[NewsSentiment], market_indicators: Dict[str, Any]) -> float:
        """ì‹œì¥ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.0
        
        # ë‰´ìŠ¤ ì‹ ë¢°ë„
        if news_sentiments:
            avg_news_confidence = sum(ns.overall_sentiment.confidence for ns in news_sentiments) / len(news_sentiments)
            confidence += avg_news_confidence * 0.6
        
        # ì‹œì¥ ì§€í‘œ ì‹ ë¢°ë„
        if market_indicators:
            confidence += 0.4
        
        return min(confidence, 1.0)
    
    def _update_sentiment_trends(self, overall_sentiment: float):
        """ê°ì • íŠ¸ë Œë“œ í†µê³„ ì—…ë°ì´íŠ¸"""
        if overall_sentiment > 0.1:
            self.stats['sentiment_trends']['positive'] += 1
        elif overall_sentiment < -0.1:
            self.stats['sentiment_trends']['negative'] += 1
        else:
            self.stats['sentiment_trends']['neutral'] += 1
    
    def _create_empty_market_sentiment(self) -> MarketSentiment:
        """ë¹ˆ ì‹œì¥ ê°ì • ê°ì²´ ìƒì„±"""
        return MarketSentiment(
            overall_sentiment=0.0,
            sentiment_trend='neutral',
            confidence_score=0.0,
            sources_analyzed=0,
            sentiment_scores=[],
            market_indicators={},
            timestamp=datetime.now()
        )
    
    def get_statistics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        total_trends = sum(self.stats['sentiment_trends'].values())
        
        return {
            'total_analyses': self.stats['total_analyses'],
            'successful_analyses': self.stats['successful_analyses'],
            'failed_analyses': self.stats['failed_analyses'],
            'success_rate': (self.stats['successful_analyses'] / self.stats['total_analyses'] * 100) if self.stats['total_analyses'] > 0 else 0,
            'average_processing_time': self.stats['average_processing_time'],
            'sentiment_distribution': {
                'positive': (self.stats['sentiment_trends']['positive'] / total_trends * 100) if total_trends > 0 else 0,
                'neutral': (self.stats['sentiment_trends']['neutral'] / total_trends * 100) if total_trends > 0 else 0,
                'negative': (self.stats['sentiment_trends']['negative'] / total_trends * 100) if total_trends > 0 else 0
            }
        }
    
    def save_statistics(self, file_path: str = "data/sentiment_analysis_stats.json"):
        """í†µê³„ ì €ì¥"""
        try:
            stats = self.get_statistics()
            stats['timestamp'] = datetime.now().isoformat()
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ’¾ ê°ì • ë¶„ì„ í†µê³„ ì €ì¥: {file_path}")
            
        except Exception as e:
            logger.error(f"âŒ ê°ì • ë¶„ì„ í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
sentiment_analyzer = MarketSentimentAnalyzer() 