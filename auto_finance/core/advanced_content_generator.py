"""
âœï¸ ê³ ë„í™”ëœ ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ
ê°ì • ë¶„ì„ ë° ì‹œì¥ ë°ì´í„°ë¥¼ í™œìš©í•œ ì „ë¬¸ì ì¸ ì½˜í…ì¸  ìƒì„±
"""

import asyncio
import json
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import re
from pathlib import Path

from auto_finance.core.ai_ensemble import ai_ensemble
from auto_finance.core.market_sentiment_analyzer import sentiment_analyzer
from auto_finance.utils.logger import setup_logger
from auto_finance.config.settings import CONTENT_CONFIG

logger = setup_logger(__name__)

@dataclass
class AdvancedContent:
    """ê³ ë„í™”ëœ ì½˜í…ì¸  ë°ì´í„° í´ë˜ìŠ¤"""
    title: str
    content: str
    summary: str
    keywords: List[str]
    sentiment_score: float
    market_impact: str
    target_audience: str
    content_type: str
    word_count: int
    seo_score: float
    readability_score: float
    generated_at: datetime
    metadata: Dict[str, Any]

@dataclass
class ContentRequest:
    """ì½˜í…ì¸  ìƒì„± ìš”ì²­"""
    articles: List[Dict[str, Any]]
    sentiment_data: Optional[Dict[str, Any]] = None
    market_data: Optional[Dict[str, Any]] = None
    target_audience: str = "general"
    content_type: str = "analysis"
    tone: str = "professional"
    length: str = "medium"
    include_charts: bool = False

class AdvancedContentGenerator:
    """ê³ ë„í™”ëœ ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.templates = self._load_templates()
        self.seo_keywords = CONTENT_CONFIG.get('seo_keywords', [])
        self.tone_options = CONTENT_CONFIG.get('tone_options', [])
        
        self.stats = {
            'total_generations': 0,
            'successful_generations': 0,
            'failed_generations': 0,
            'average_processing_time': 0.0,
            'content_types': {},
            'audience_types': {}
        }
    
    def _load_templates(self) -> Dict[str, str]:
        """í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            'analysis': """
# {{title}}

## ğŸ“Š ì‹œì¥ í˜„í™©
{{market_overview}}

## ğŸ” í•µì‹¬ ë¶„ì„
{{core_analysis}}

## ğŸ’¡ íˆ¬ìì ê´€ì 
{{investment_insights}}

## âš ï¸ ë¦¬ìŠ¤í¬ ìš”ì¸
{{risk_factors}}

## ğŸ“ˆ ì „ë§
{{outlook}}

**í‚¤ì›Œë“œ**: {{keywords}}
**ìƒì„±ì¼ì‹œ**: {{timestamp}}
**ì‹œì¥ ê°ì •**: {{sentiment}}
            """,
            
            'summary': """
## ğŸ“° ë‰´ìŠ¤ ìš”ì•½

{{summary_content}}

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸
{{key_points}}

## ğŸ“Š ì‹œì¥ ì˜í–¥ë„
{{market_impact}}

**ìƒì„±ì¼ì‹œ**: {{timestamp}}
            """,
            
            'report': """
# {{title}}

## ğŸ“‹ ê°œìš”
{{overview}}

## ğŸ“Š ë°ì´í„° ë¶„ì„
{{data_analysis}}

## ğŸ” ì‹¬ì¸µ ë¶„ì„
{{deep_analysis}}

## ğŸ’¼ íˆ¬ì ì „ëµ
{{investment_strategy}}

## ğŸ“ˆ ê²°ë¡ 
{{conclusion}}

**í‚¤ì›Œë“œ**: {{keywords}}
**ìƒì„±ì¼ì‹œ**: {{timestamp}}
            """
        }
    
    async def generate_advanced_content(self, request: ContentRequest) -> List[AdvancedContent]:
        """ê³ ë„í™”ëœ ì½˜í…ì¸  ìƒì„±"""
        logger.info(f"âœï¸ ê³ ë„í™”ëœ ì½˜í…ì¸  ìƒì„± ì‹œì‘: {len(request.articles)}ê°œ ê¸°ì‚¬")
        
        start_time = time.time()
        results = []
        
        try:
            # ê°ì • ë¶„ì„ ìˆ˜í–‰
            if not request.sentiment_data:
                news_sentiments = await sentiment_analyzer.analyze_news_sentiment(request.articles)
                market_sentiment = await sentiment_analyzer.analyze_market_sentiment(news_sentiments)
            else:
                market_sentiment = request.sentiment_data
            
            # ê¸°ì‚¬ë³„ ì½˜í…ì¸  ìƒì„±
            for i, article in enumerate(request.articles):
                try:
                    content = await self._generate_single_content(
                        article, market_sentiment, request, i
                    )
                    results.append(content)
                    self.stats['successful_generations'] += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
                    self.stats['failed_generations'] += 1
                    continue
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self.stats['total_generations'] += len(request.articles)
            self.stats['average_processing_time'] = processing_time / len(request.articles) if request.articles else 0
            
            # ì½˜í…ì¸  íƒ€ì…ë³„ í†µê³„
            content_type = request.content_type
            self.stats['content_types'][content_type] = self.stats['content_types'].get(content_type, 0) + len(results)
            
            # ëŒ€ìƒ ë…ìë³„ í†µê³„
            audience = request.target_audience
            self.stats['audience_types'][audience] = self.stats['audience_types'].get(audience, 0) + len(results)
            
            logger.info(f"âœ… ê³ ë„í™”ëœ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {len(results)}ê°œ ì„±ê³µ, {processing_time:.2f}ì´ˆ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ê³ ë„í™”ëœ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    async def _generate_single_content(self, article: Dict[str, Any], 
                                     market_sentiment: Any, 
                                     request: ContentRequest, 
                                     index: int) -> AdvancedContent:
        """ë‹¨ì¼ ì½˜í…ì¸  ìƒì„±"""
        # ê¸°ì‚¬ ì •ë³´ ì¶”ì¶œ
        title = article.get('title', '')
        content = article.get('content', '')
        source = article.get('source', '')
        
        # ê°ì • ë¶„ì„
        article_sentiment = await sentiment_analyzer._analyze_single_article(article)
        
        # AI ì•™ìƒë¸”ì„ ì‚¬ìš©í•œ ì½˜í…ì¸  ìƒì„±
        ai_prompt = self._create_ai_prompt(article, market_sentiment, request)
        ai_response = await ai_ensemble.generate_content_ensemble(ai_prompt, 'content_generation')
        
        # ì½˜í…ì¸  í›„ì²˜ë¦¬
        processed_content = self._post_process_content(ai_response.final_content, request)
        
        # SEO ìµœì í™”
        seo_optimized_content = self._optimize_for_seo(processed_content, article)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        seo_score = self._calculate_seo_score(seo_optimized_content)
        readability_score = self._calculate_readability_score(seo_optimized_content)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(seo_optimized_content, article)
        
        # ì‹œì¥ ì˜í–¥ë„ ë¶„ì„
        market_impact = self._analyze_market_impact(article_sentiment, market_sentiment)
        
        return AdvancedContent(
            title=self._generate_title(title, article_sentiment),
            content=seo_optimized_content,
            summary=self._generate_summary(seo_optimized_content),
            keywords=keywords,
            sentiment_score=article_sentiment.overall_sentiment.compound,
            market_impact=market_impact,
            target_audience=request.target_audience,
            content_type=request.content_type,
            word_count=len(seo_optimized_content.split()),
            seo_score=seo_score,
            readability_score=readability_score,
            generated_at=datetime.now(),
            metadata={
                'source': source,
                'ai_confidence': ai_response.confidence_score,
                'processing_time': ai_response.processing_time,
                'model_contributions': ai_response.model_contributions
            }
        )
    
    def _create_ai_prompt(self, article: Dict[str, Any], market_sentiment: Any, request: ContentRequest) -> str:
        """AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        title = article.get('title', '')
        content = article.get('content', '')
        
        prompt = f"""
        ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ íˆ¬ì ë¶„ì„ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
        ì œëª©: {title}
        ë‚´ìš©: {content}
        
        ì‹œì¥ ê°ì •: {market_sentiment.overall_sentiment:.3f} ({market_sentiment.sentiment_trend})
        
        ìš”êµ¬ì‚¬í•­:
        - ëŒ€ìƒ ë…ì: {request.target_audience}
        - ì½˜í…ì¸  íƒ€ì…: {request.content_type}
        - í†¤: {request.tone}
        - ê¸¸ì´: {request.length} ({self._get_length_guide(request.length)})
        
        ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
        1. ì‹œì¥ í˜„í™© ë¶„ì„
        2. í•µì‹¬ í¬ì¸íŠ¸ ë¶„ì„
        3. íˆ¬ìì ê´€ì ì—ì„œì˜ ì¸ì‚¬ì´íŠ¸
        4. ë¦¬ìŠ¤í¬ ìš”ì¸
        5. í–¥í›„ ì „ë§
        
        ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ê³ , êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        return prompt
    
    def _get_length_guide(self, length: str) -> str:
        """ê¸¸ì´ ê°€ì´ë“œ"""
        guides = {
            'short': '500-800ì',
            'medium': '800-1200ì',
            'long': '1200-1800ì'
        }
        return guides.get(length, '800-1200ì')
    
    def _post_process_content(self, content: str, request: ContentRequest) -> str:
        """ì½˜í…ì¸  í›„ì²˜ë¦¬"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        content = re.sub(r'\n\s*\n', '\n\n', content)
        
        # ì œëª© í˜•ì‹ í†µì¼
        content = re.sub(r'^#\s*', '# ', content, flags=re.MULTILINE)
        
        # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ í†µì¼
        content = re.sub(r'^\s*[-*]\s*', '- ', content, flags=re.MULTILINE)
        
        # ê¸¸ì´ ì¡°ì •
        target_length = self._get_target_length(request.length)
        current_length = len(content)
        
        if current_length > target_length * 1.2:
            # ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
            sentences = content.split('.')
            content = '. '.join(sentences[:len(sentences)//2]) + '.'
        elif current_length < target_length * 0.8:
            # ë„ˆë¬´ ì§§ìœ¼ë©´ í™•ì¥
            content += "\n\nì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        return content.strip()
    
    def _get_target_length(self, length: str) -> int:
        """ëª©í‘œ ê¸¸ì´"""
        lengths = {
            'short': 600,
            'medium': 1000,
            'long': 1500
        }
        return lengths.get(length, 1000)
    
    def _optimize_for_seo(self, content: str, article: Dict[str, Any]) -> str:
        """SEO ìµœì í™”"""
        # í‚¤ì›Œë“œ ë°€ë„ ìµœì í™”
        title_keywords = self._extract_keywords(article.get('title', ''), [])
        
        for keyword in title_keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ
            if keyword not in content:
                # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì ì ˆí•œ ìœ„ì¹˜ì— ì¶”ê°€
                content = self._insert_keyword_naturally(content, keyword)
        
        # í—¤ë”© íƒœê·¸ ìµœì í™”
        content = self._optimize_headings(content)
        
        # ë©”íƒ€ ì„¤ëª… ì¶”ê°€
        meta_description = self._generate_meta_description(content)
        content = f"<!-- Meta Description: {meta_description} -->\n\n{content}"
        
        return content
    
    def _insert_keyword_naturally(self, content: str, keyword: str) -> str:
        """ìì—°ìŠ¤ëŸ½ê²Œ í‚¤ì›Œë“œ ì‚½ì…"""
        sentences = content.split('.')
        
        # ì ì ˆí•œ ë¬¸ì¥ì— í‚¤ì›Œë“œ ì‚½ì…
        for i, sentence in enumerate(sentences):
            if len(sentence) > 50 and keyword not in sentence:
                # ë¬¸ì¥ ì¤‘ê°„ì— í‚¤ì›Œë“œ ì‚½ì…
                words = sentence.split()
                if len(words) > 5:
                    insert_pos = len(words) // 2
                    words.insert(insert_pos, keyword)
                    sentences[i] = ' '.join(words)
                    break
        
        return '. '.join(sentences)
    
    def _optimize_headings(self, content: str) -> str:
        """í—¤ë”© íƒœê·¸ ìµœì í™”"""
        # H1 íƒœê·¸ëŠ” í•˜ë‚˜ë§Œ
        h1_count = content.count('# ')
        if h1_count > 1:
            content = re.sub(r'^# ', '## ', content, flags=re.MULTILINE)
        
        # H2, H3 íƒœê·¸ ì ì ˆíˆ ë°°ì¹˜
        lines = content.split('\n')
        optimized_lines = []
        
        for line in lines:
            if line.startswith('## '):
                # H2 íƒœê·¸ëŠ” ì£¼ìš” ì„¹ì…˜ì—ë§Œ
                if any(keyword in line.lower() for keyword in ['ë¶„ì„', 'ì „ë§', 'ì „ëµ', 'ë¦¬ìŠ¤í¬']):
                    optimized_lines.append(line)
                else:
                    optimized_lines.append(line.replace('## ', '### '))
            else:
                optimized_lines.append(line)
        
        return '\n'.join(optimized_lines)
    
    def _generate_meta_description(self, content: str) -> str:
        """ë©”íƒ€ ì„¤ëª… ìƒì„±"""
        # ì²« ë²ˆì§¸ ë¬¸ë‹¨ì—ì„œ ì¶”ì¶œ
        paragraphs = content.split('\n\n')
        if paragraphs:
            first_para = paragraphs[0]
            # HTML íƒœê·¸ ì œê±°
            clean_para = re.sub(r'<[^>]+>', '', first_para)
            # 150ìë¡œ ì œí•œ
            if len(clean_para) > 150:
                clean_para = clean_para[:147] + '...'
            return clean_para
        return "ì£¼ì‹ íˆ¬ì ë¶„ì„ ë° ì‹œì¥ ì „ë§"
    
    def _calculate_seo_score(self, content: str) -> float:
        """SEO ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # í‚¤ì›Œë“œ ë°€ë„
        keyword_density = self._calculate_keyword_density(content)
        score += min(keyword_density * 10, 30)
        
        # í—¤ë”© êµ¬ì¡°
        heading_score = self._calculate_heading_score(content)
        score += heading_score
        
        # ì½˜í…ì¸  ê¸¸ì´
        length_score = min(len(content) / 100, 20)
        score += length_score
        
        # ê°€ë…ì„±
        readability = self._calculate_readability_score(content)
        score += readability * 20
        
        return min(score, 100.0)
    
    def _calculate_keyword_density(self, content: str) -> float:
        """í‚¤ì›Œë“œ ë°€ë„ ê³„ì‚°"""
        total_words = len(content.split())
        if total_words == 0:
            return 0.0
        
        keyword_count = 0
        for keyword in self.seo_keywords:
            keyword_count += content.lower().count(keyword.lower())
        
        return keyword_count / total_words
    
    def _calculate_heading_score(self, content: str) -> float:
        """í—¤ë”© ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # H1 íƒœê·¸ (í•˜ë‚˜ë§Œ)
        h1_count = content.count('# ')
        if h1_count == 1:
            score += 10
        elif h1_count > 1:
            score -= 5
        
        # H2 íƒœê·¸ (3-5ê°œ ê¶Œì¥)
        h2_count = content.count('## ')
        if 3 <= h2_count <= 5:
            score += 15
        elif h2_count > 0:
            score += 10
        
        # H3 íƒœê·¸
        h3_count = content.count('### ')
        if h3_count > 0:
            score += 5
        
        return score
    
    def _calculate_readability_score(self, content: str) -> float:
        """ê°€ë…ì„± ì ìˆ˜ ê³„ì‚°"""
        sentences = content.split('.')
        words = content.split()
        
        if not sentences or not words:
            return 0.0
        
        # í‰ê·  ë¬¸ì¥ ê¸¸ì´
        avg_sentence_length = len(words) / len(sentences)
        
        # ê°€ë…ì„± ì ìˆ˜ (ë¬¸ì¥ì´ ì§§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        if avg_sentence_length <= 15:
            score = 1.0
        elif avg_sentence_length <= 20:
            score = 0.8
        elif avg_sentence_length <= 25:
            score = 0.6
        else:
            score = 0.4
        
        return score
    
    def _extract_keywords(self, content: str, article: Dict[str, Any]) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ê¸°ì‚¬ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        title = article.get('title', '')
        title_keywords = self._extract_keywords_from_text(title)
        keywords.extend(title_keywords)
        
        # ì½˜í…ì¸ ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        content_keywords = self._extract_keywords_from_text(content)
        keywords.extend(content_keywords)
        
        # SEO í‚¤ì›Œë“œì™€ ë§¤ì¹­
        matched_keywords = [kw for kw in self.seo_keywords if kw in content.lower()]
        keywords.extend(matched_keywords)
        
        # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 10ê°œ ì„ íƒ
        unique_keywords = list(set(keywords))
        return unique_keywords[:10]
    
    def _extract_keywords_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš©)
        keywords = []
        
        # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
        financial_keywords = [
            'ì£¼ì‹', 'íˆ¬ì', 'ê²½ì œ', 'ê¸ˆìœµ', 'ì‹œì¥', 'ë¶„ì„', 'ì „ë§', 'ì „ëµ',
            'í¬íŠ¸í´ë¦¬ì˜¤', 'ë¦¬ìŠ¤í¬', 'ìˆ˜ìµë¥ ', 'ì„±ì¥', 'ê°€ì¹˜', 'ë°°ë‹¹',
            'ìƒìŠ¹', 'í•˜ë½', 'ê¸‰ë“±', 'ê¸‰ë½', 'í˜¸ì¬', 'ì•…ì¬'
        ]
        
        for keyword in financial_keywords:
            if keyword in text:
                keywords.append(keyword)
        
        return keywords
    
    def _analyze_market_impact(self, article_sentiment: Any, market_sentiment: Any) -> str:
        """ì‹œì¥ ì˜í–¥ë„ ë¶„ì„"""
        article_compound = article_sentiment.overall_sentiment.compound
        market_compound = market_sentiment.overall_sentiment
        
        if article_compound > 0.3 and market_compound > 0.1:
            return "ê°•í•œ ê¸ì •ì  ì˜í–¥"
        elif article_compound > 0.1 and market_compound > -0.1:
            return "ê¸ì •ì  ì˜í–¥"
        elif article_compound < -0.3 and market_compound < -0.1:
            return "ê°•í•œ ë¶€ì •ì  ì˜í–¥"
        elif article_compound < -0.1 and market_compound < 0.1:
            return "ë¶€ì •ì  ì˜í–¥"
        else:
            return "ì¤‘ë¦½ì  ì˜í–¥"
    
    def _generate_title(self, original_title: str, sentiment: Any) -> str:
        """ì œëª© ìƒì„±"""
        # ê°ì •ì— ë”°ë¥¸ ì œëª© ìˆ˜ì •
        compound = sentiment.overall_sentiment.compound
        
        if compound > 0.2:
            prefix = "ğŸ“ˆ ê¸ì •ì  ì „ë§: "
        elif compound < -0.2:
            prefix = "ğŸ“‰ ì£¼ì˜ í•„ìš”: "
        else:
            prefix = "ğŸ“Š ì‹œì¥ ë¶„ì„: "
        
        return prefix + original_title
    
    def _generate_summary(self, content: str) -> str:
        """ìš”ì•½ ìƒì„±"""
        # ì²« ë²ˆì§¸ ë¬¸ë‹¨ì„ ìš”ì•½ìœ¼ë¡œ ì‚¬ìš©
        paragraphs = content.split('\n\n')
        if paragraphs:
            summary = paragraphs[0]
            # HTML íƒœê·¸ ì œê±°
            summary = re.sub(r'<[^>]+>', '', summary)
            # 200ìë¡œ ì œí•œ
            if len(summary) > 200:
                summary = summary[:197] + '...'
            return summary
        return "ìƒì„¸í•œ ì‹œì¥ ë¶„ì„ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”."
    
    def get_statistics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        return {
            'total_generations': self.stats['total_generations'],
            'successful_generations': self.stats['successful_generations'],
            'failed_generations': self.stats['failed_generations'],
            'success_rate': (self.stats['successful_generations'] / self.stats['total_generations'] * 100) if self.stats['total_generations'] > 0 else 0,
            'average_processing_time': self.stats['average_processing_time'],
            'content_types': self.stats['content_types'],
            'audience_types': self.stats['audience_types']
        }
    
    def save_statistics(self, file_path: str = "data/content_generation_stats.json"):
        """í†µê³„ ì €ì¥"""
        try:
            stats = self.get_statistics()
            stats['timestamp'] = datetime.now().isoformat()
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ’¾ ì½˜í…ì¸  ìƒì„± í†µê³„ ì €ì¥: {file_path}")
            
        except Exception as e:
            logger.error(f"âŒ ì½˜í…ì¸  ìƒì„± í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
advanced_content_generator = AdvancedContentGenerator() 