"""
ğŸ” ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ
í¬ë¡¤ë§ ë°ì´í„°ì˜ ì‹ ë¢°ì„±ì„ ë³´ì¥í•˜ëŠ” ì´ì¤‘ ê²€ì¦ ì‹œìŠ¤í…œ
"""

import asyncio
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import hashlib

# ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from auto_finance.utils.logger import setup_logger
from auto_finance.utils.error_handler import ErrorHandler
from auto_finance.utils.cache_manager import cache_manager

logger = setup_logger(__name__)

class ValidationStatus(Enum):
    """ê²€ì¦ ìƒíƒœ"""
    PENDING = "pending"
    VALIDATING = "validating"
    VALID = "valid"
    INVALID = "invalid"
    SUSPICIOUS = "suspicious"
    ERROR = "error"

class DataSource(Enum):
    """ë°ì´í„° ì†ŒìŠ¤"""
    PRIMARY = "primary"
    SECONDARY = "secondary"
    CACHE = "cache"

@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    data_id: str
    status: ValidationStatus
    confidence_score: float  # 0.0 ~ 1.0
    validation_time: datetime
    primary_data: Dict[str, Any]
    secondary_data: Optional[Dict[str, Any]] = None
    differences: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

class DataValidator:
    """ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.error_handler = ErrorHandler()
        
        # ê²€ì¦ ì„¤ì •
        self.validation_config = {
            'max_retries': 3,
            'retry_delay': 5,
            'similarity_threshold': 0.8,
            'confidence_threshold': 0.7,
            'cache_ttl': 1800,  # 30ë¶„
            'validation_timeout': 60  # 60ì´ˆ
        }
        
        # ê²€ì¦ í†µê³„
        self.stats = {
            'total_validations': 0,
            'valid_data': 0,
            'invalid_data': 0,
            'suspicious_data': 0,
            'validation_errors': 0,
            'average_confidence': 0.0,
            'average_validation_time': 0.0
        }
        
        # ê²€ì¦ íˆìŠ¤í† ë¦¬
        self.validation_history: List[ValidationResult] = []
        
        logger.info("ğŸ” ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def validate_crawled_data(self, primary_data: Dict[str, Any], 
                                   data_source: str = "unknown") -> ValidationResult:
        """í¬ë¡¤ë§ ë°ì´í„° ê²€ì¦"""
        start_time = time.time()
        data_id = self._generate_data_id(primary_data, data_source)
        
        logger.info(f"ğŸ” ë°ì´í„° ê²€ì¦ ì‹œì‘: {data_id}")
        
        try:
            # 1ë‹¨ê³„: ê¸°ë³¸ ë°ì´í„° ê²€ì¦
            basic_validation = self._validate_basic_structure(primary_data)
            if not basic_validation['is_valid']:
                return self._create_invalid_result(
                    data_id, primary_data, basic_validation['errors']
                )
            
            # 2ë‹¨ê³„: ì´ì¤‘ í¬ë¡¤ë§ ê²€ì¦
            secondary_data = await self._perform_secondary_crawling(data_source)
            
            # 3ë‹¨ê³„: ë°ì´í„° ë¹„êµ ë° ì¼ê´€ì„± ê²€ì‚¬
            comparison_result = self._compare_datasets(primary_data, secondary_data)
            
            # 4ë‹¨ê³„: ì´ìƒì¹˜ íƒì§€
            anomaly_result = self._detect_anomalies(primary_data)
            
            # 5ë‹¨ê³„: ìµœì¢… ê²€ì¦ ê²°ê³¼ ìƒì„±
            validation_result = self._create_validation_result(
                data_id, primary_data, secondary_data, 
                comparison_result, anomaly_result, start_time
            )
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(validation_result, time.time() - start_time)
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.validation_history.append(validation_result)
            
            logger.info(f"âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {data_id} (ì‹ ë¢°ë„: {validation_result.confidence_score:.2f})")
            return validation_result
            
        except Exception as e:
            self.error_handler.handle_error(e, f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {data_id}")
            logger.error(f"âŒ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {data_id} - {e}")
            
            return self._create_error_result(data_id, primary_data, str(e))
    
    def _validate_basic_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ë³¸ ë°ì´í„° êµ¬ì¡° ê²€ì¦"""
        result = {
            'is_valid': True,
            'errors': [],
            'warnings': []
        }
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['ì´ì ', 'ì´ì™„ë£Œ', 'ìˆ˜ë½ë¥ ']
        for field in required_fields:
            if field not in data:
                result['errors'].append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                result['is_valid'] = False
        
        # ë°ì´í„° íƒ€ì… ê²€ì¦
        if 'ì´ì ' in data and not isinstance(data['ì´ì '], (int, float)):
            result['errors'].append("ì´ì ì´ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤")
            result['is_valid'] = False
        
        if 'ìˆ˜ë½ë¥ ' in data and not isinstance(data['ìˆ˜ë½ë¥ '], (int, float)):
            result['errors'].append("ìˆ˜ë½ë¥ ì´ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤")
            result['is_valid'] = False
        
        # ë°ì´í„° ë²”ìœ„ ê²€ì¦
        if 'ì´ì ' in data and isinstance(data['ì´ì '], (int, float)):
            if data['ì´ì '] < 0 or data['ì´ì '] > 200:
                result['warnings'].append(f"ë¹„ì •ìƒì ì¸ ì´ì : {data['ì´ì ']}")
        
        if 'ìˆ˜ë½ë¥ ' in data and isinstance(data['ìˆ˜ë½ë¥ '], (int, float)):
            if data['ìˆ˜ë½ë¥ '] < 0 or data['ìˆ˜ë½ë¥ '] > 100:
                result['errors'].append(f"ë¹„ì •ìƒì ì¸ ìˆ˜ë½ë¥ : {data['ìˆ˜ë½ë¥ ']}")
                result['is_valid'] = False
        
        # í”¼í¬ ë°ì´í„° ê²€ì¦
        peak_fields = ['ì•„ì¹¨ì ì‹¬í”¼í¬', 'ì˜¤í›„ë…¼í”¼í¬', 'ì €ë…í”¼í¬', 'ì‹¬ì•¼ë…¼í”¼í¬']
        for peak in peak_fields:
            if peak in data:
                peak_data = data[peak]
                if not isinstance(peak_data, dict):
                    result['errors'].append(f"{peak} ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")
                    result['is_valid'] = False
                elif 'current' not in peak_data or 'target' not in peak_data:
                    result['warnings'].append(f"{peak} í•„ìˆ˜ í•˜ìœ„ í•„ë“œ ëˆ„ë½")
        
        return result
    
    async def _perform_secondary_crawling(self, data_source: str) -> Optional[Dict[str, Any]]:
        """ì´ì¤‘ í¬ë¡¤ë§ ìˆ˜í–‰"""
        try:
            logger.info(f"ğŸ”„ ì´ì¤‘ í¬ë¡¤ë§ ì‹œì‘: {data_source}")
            
            # ìºì‹œëœ ë°ì´í„° í™•ì¸
            cache_key = f"secondary_crawl_{data_source}_{datetime.now().strftime('%Y%m%d_%H')}"
            cached_data = cache_manager.get(cache_key)
            
            if cached_data:
                logger.info("ğŸ’¾ ìºì‹œëœ ì´ì¤‘ í¬ë¡¤ë§ ë°ì´í„° ì‚¬ìš©")
                return cached_data
            
            # ì‹¤ì œ ì´ì¤‘ í¬ë¡¤ë§ ìˆ˜í–‰ (ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜)
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‹¤ë¥¸ í¬ë¡¤ë§ ë°©ë²•ì´ë‚˜ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©
            await asyncio.sleep(2)  # í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜
            
            # ì‹œë®¬ë ˆì´ì…˜ëœ ì´ì¤‘ í¬ë¡¤ë§ ê²°ê³¼
            secondary_data = self._simulate_secondary_crawl(data_source)
            
            # ìºì‹œì— ì €ì¥
            if secondary_data:
                cache_manager.set(cache_key, secondary_data, ttl=self.validation_config['cache_ttl'])
            
            return secondary_data
            
        except Exception as e:
            logger.error(f"âŒ ì´ì¤‘ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None
    
    def _simulate_secondary_crawl(self, data_source: str) -> Dict[str, Any]:
        """ì´ì¤‘ í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜"""
        # ì‹¤ì œë¡œëŠ” ë‹¤ë¥¸ í¬ë¡¤ë§ ë°©ë²•ì„ ì‚¬ìš©í•´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ì•½ê°„ì˜ ë³€ë™ì„ ì£¼ì–´ ì‹œë®¬ë ˆì´ì…˜
        import random
        
        base_data = {
            'ì´ì ': random.randint(80, 120),
            'ë¬¼ëŸ‰ì ìˆ˜': random.randint(30, 50),
            'ìˆ˜ë½ë¥ ì ìˆ˜': random.randint(40, 60),
            'ì´ì™„ë£Œ': random.randint(50, 100),
            'ì´ê±°ì ˆ': random.randint(0, 20),
            'ìˆ˜ë½ë¥ ': random.uniform(80.0, 95.0),
            'ì•„ì¹¨ì ì‹¬í”¼í¬': {"current": random.randint(10, 20), "target": 15},
            'ì˜¤í›„ë…¼í”¼í¬': {"current": random.randint(5, 15), "target": 10},
            'ì €ë…í”¼í¬': {"current": random.randint(15, 25), "target": 20},
            'ì‹¬ì•¼ë…¼í”¼í¬': {"current": random.randint(3, 10), "target": 8},
            'riders': [],
            'timestamp': datetime.now().isoformat()
        }
        
        return base_data
    
    def _compare_datasets(self, primary: Dict[str, Any], 
                         secondary: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ ë¹„êµ"""
        result = {
            'similarity_score': 0.0,
            'differences': [],
            'is_consistent': False
        }
        
        if not secondary:
            result['differences'].append("ì´ì¤‘ í¬ë¡¤ë§ ë°ì´í„° ì—†ìŒ")
            return result
        
        # ì£¼ìš” í•„ë“œ ë¹„êµ
        key_fields = ['ì´ì ', 'ì´ì™„ë£Œ', 'ìˆ˜ë½ë¥ ']
        differences = []
        total_difference = 0
        
        for field in key_fields:
            if field in primary and field in secondary:
                primary_val = primary[field]
                secondary_val = secondary[field]
                
                if isinstance(primary_val, (int, float)) and isinstance(secondary_val, (int, float)):
                    diff = abs(primary_val - secondary_val)
                    if diff > 0:
                        differences.append(f"{field}: {primary_val} vs {secondary_val} (ì°¨ì´: {diff})")
                        total_difference += diff
        
        # í”¼í¬ ë°ì´í„° ë¹„êµ
        peak_fields = ['ì•„ì¹¨ì ì‹¬í”¼í¬', 'ì˜¤í›„ë…¼í”¼í¬', 'ì €ë…í”¼í¬', 'ì‹¬ì•¼ë…¼í”¼í¬']
        for peak in peak_fields:
            if peak in primary and peak in secondary:
                p_primary = primary[peak]
                p_secondary = secondary[peak]
                
                if isinstance(p_primary, dict) and isinstance(p_secondary, dict):
                    if 'current' in p_primary and 'current' in p_secondary:
                        diff = abs(p_primary['current'] - p_secondary['current'])
                        if diff > 2:  # 2ê°œ ì´ìƒ ì°¨ì´ë‚˜ë©´ ì°¨ì´ë¡œ ê¸°ë¡
                            differences.append(f"{peak}.current: {p_primary['current']} vs {p_secondary['current']}")
                            total_difference += diff
        
        # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
        if differences:
            result['differences'] = differences
            # ì°¨ì´ê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ìœ ì‚¬ë„
            result['similarity_score'] = max(0.0, 1.0 - (total_difference / 100.0))
        else:
            result['similarity_score'] = 1.0
        
        result['is_consistent'] = result['similarity_score'] >= self.validation_config['similarity_threshold']
        
        return result
    
    def _detect_anomalies(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì´ìƒì¹˜ íƒì§€"""
        result = {
            'anomalies': [],
            'risk_score': 0.0
        }
        
        # ê¸‰ê²©í•œ ë³€í™” íƒì§€
        if 'ì´ì ' in data:
            score = data['ì´ì ']
            if score < 50:
                result['anomalies'].append(f"ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ì€ ì´ì : {score}")
                result['risk_score'] += 0.3
            elif score > 150:
                result['anomalies'].append(f"ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ì´ì : {score}")
                result['risk_score'] += 0.2
        
        if 'ìˆ˜ë½ë¥ ' in data:
            rate = data['ìˆ˜ë½ë¥ ']
            if rate < 50:
                result['anomalies'].append(f"ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ì€ ìˆ˜ë½ë¥ : {rate}%")
                result['risk_score'] += 0.4
            elif rate > 99:
                result['anomalies'].append(f"ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ìˆ˜ë½ë¥ : {rate}%")
                result['risk_score'] += 0.2
        
        # í”¼í¬ ë°ì´í„° ì´ìƒì¹˜ íƒì§€
        peak_fields = ['ì•„ì¹¨ì ì‹¬í”¼í¬', 'ì˜¤í›„ë…¼í”¼í¬', 'ì €ë…í”¼í¬', 'ì‹¬ì•¼ë…¼í”¼í¬']
        for peak in peak_fields:
            if peak in data:
                peak_data = data[peak]
                if isinstance(peak_data, dict) and 'current' in peak_data:
                    current = peak_data['current']
                    target = peak_data.get('target', 0)
                    
                    # ëª©í‘œ ëŒ€ë¹„ 50% ì´ìƒ ì°¨ì´ë‚˜ëŠ” ê²½ìš°
                    if target > 0:
                        ratio = abs(current - target) / target
                        if ratio > 0.5:
                            result['anomalies'].append(f"{peak} ëª©í‘œ ëŒ€ë¹„ í° ì°¨ì´: {current}/{target}")
                            result['risk_score'] += 0.1
        
        # ë¼ì´ë” ë°ì´í„° ì´ìƒì¹˜
        if 'riders' in data and isinstance(data['riders'], list):
            if len(data['riders']) == 0:
                result['anomalies'].append("ë¼ì´ë” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                result['risk_score'] += 0.2
            elif len(data['riders']) > 100:
                result['anomalies'].append(f"ë¹„ì •ìƒì ìœ¼ë¡œ ë§ì€ ë¼ì´ë”: {len(data['riders'])}ëª…")
                result['risk_score'] += 0.1
        
        result['risk_score'] = min(1.0, result['risk_score'])
        return result
    
    def _create_validation_result(self, data_id: str, primary_data: Dict[str, Any],
                                 secondary_data: Optional[Dict[str, Any]],
                                 comparison_result: Dict[str, Any],
                                 anomaly_result: Dict[str, Any],
                                 start_time: float) -> ValidationResult:
        """ê²€ì¦ ê²°ê³¼ ìƒì„±"""
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = 1.0
        
        # ì¼ê´€ì„± ì ìˆ˜ ë°˜ì˜
        confidence_score *= comparison_result['similarity_score']
        
        # ì´ìƒì¹˜ ì ìˆ˜ ë°˜ì˜
        confidence_score *= (1.0 - anomaly_result['risk_score'])
        
        # ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜
        confidence_score = max(0.0, min(1.0, confidence_score))
        
        # ìƒíƒœ ê²°ì •
        if confidence_score >= self.validation_config['confidence_threshold']:
            status = ValidationStatus.VALID
        elif confidence_score >= 0.5:
            status = ValidationStatus.SUSPICIOUS
        else:
            status = ValidationStatus.INVALID
        
        # ê²½ê³  ë° ì˜¤ë¥˜ ë©”ì‹œì§€ ìˆ˜ì§‘
        warnings = []
        errors = []
        
        if comparison_result['differences']:
            warnings.extend(comparison_result['differences'])
        
        if anomaly_result['anomalies']:
            warnings.extend(anomaly_result['anomalies'])
        
        return ValidationResult(
            data_id=data_id,
            status=status,
            confidence_score=confidence_score,
            validation_time=datetime.now(),
            primary_data=primary_data,
            secondary_data=secondary_data,
            differences=comparison_result['differences'],
            warnings=warnings,
            errors=errors,
            metadata={
                'comparison_score': comparison_result['similarity_score'],
                'anomaly_risk': anomaly_result['risk_score'],
                'validation_duration': time.time() - start_time
            }
        )
    
    def _create_invalid_result(self, data_id: str, data: Dict[str, Any], 
                              errors: List[str]) -> ValidationResult:
        """ë¬´íš¨í•œ ê²°ê³¼ ìƒì„±"""
        return ValidationResult(
            data_id=data_id,
            status=ValidationStatus.INVALID,
            confidence_score=0.0,
            validation_time=datetime.now(),
            primary_data=data,
            errors=errors
        )
    
    def _create_error_result(self, data_id: str, data: Dict[str, Any], 
                            error: str) -> ValidationResult:
        """ì˜¤ë¥˜ ê²°ê³¼ ìƒì„±"""
        return ValidationResult(
            data_id=data_id,
            status=ValidationStatus.ERROR,
            confidence_score=0.0,
            validation_time=datetime.now(),
            primary_data=data,
            errors=[error]
        )
    
    def _generate_data_id(self, data: Dict[str, Any], source: str) -> str:
        """ë°ì´í„° ID ìƒì„±"""
        # ì£¼ìš” í•„ë“œë“¤ì„ ì¡°í•©í•˜ì—¬ ID ìƒì„±
        key_data = {
            'ì´ì ': data.get('ì´ì ', 0),
            'ì´ì™„ë£Œ': data.get('ì´ì™„ë£Œ', 0),
            'ìˆ˜ë½ë¥ ': data.get('ìˆ˜ë½ë¥ ', 0),
            'source': source,
            'timestamp': datetime.now().strftime('%Y%m%d_%H%M')
        }
        
        data_str = json.dumps(key_data, sort_keys=True)
        return hashlib.md5(data_str.encode()).hexdigest()[:12]
    
    def _update_stats(self, result: ValidationResult, processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats['total_validations'] += 1
        
        if result.status == ValidationStatus.VALID:
            self.stats['valid_data'] += 1
        elif result.status == ValidationStatus.INVALID:
            self.stats['invalid_data'] += 1
        elif result.status == ValidationStatus.SUSPICIOUS:
            self.stats['suspicious_data'] += 1
        elif result.status == ValidationStatus.ERROR:
            self.stats['validation_errors'] += 1
        
        # í‰ê·  ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
        total_confidence = self.stats['average_confidence'] * (self.stats['total_validations'] - 1)
        self.stats['average_confidence'] = (total_confidence + result.confidence_score) / self.stats['total_validations']
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        total_time = self.stats['average_validation_time'] * (self.stats['total_validations'] - 1)
        self.stats['average_validation_time'] = (total_time + processing_time) / self.stats['total_validations']
    
    def get_validation_stats(self) -> Dict[str, Any]:
        """ê²€ì¦ í†µê³„ ë°˜í™˜"""
        return {
            'stats': self.stats,
            'success_rate': (self.stats['valid_data'] / self.stats['total_validations'] * 100) 
                           if self.stats['total_validations'] > 0 else 0,
            'recent_validations': len(self.validation_history[-10:])  # ìµœê·¼ 10ê°œ
        }
    
    def get_validation_history(self, limit: int = 50) -> List[ValidationResult]:
        """ê²€ì¦ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.validation_history[-limit:]
    
    def is_data_trustworthy(self, result: ValidationResult) -> bool:
        """ë°ì´í„° ì‹ ë¢°ì„± íŒë‹¨"""
        return (result.status == ValidationStatus.VALID and 
                result.confidence_score >= self.validation_config['confidence_threshold'])
    
    def get_recommendation(self, result: ValidationResult) -> str:
        """ê²€ì¦ ê²°ê³¼ì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­"""
        if result.status == ValidationStatus.VALID:
            return "âœ… ë°ì´í„°ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ìƒì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”."
        elif result.status == ValidationStatus.SUSPICIOUS:
            return "âš ï¸ ë°ì´í„°ì— ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì ì´ ìˆìŠµë‹ˆë‹¤. ì¬í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif result.status == ValidationStatus.INVALID:
            return "âŒ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
        else:
            return "ğŸš¨ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ì ê²€í•˜ì„¸ìš”." 