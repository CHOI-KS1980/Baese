#!/usr/bin/env python3
"""
ğŸ§¹ ë¡œê·¸ íŒŒì¼ ìë™ ê´€ë¦¬ ë° ìµœì í™” ì‹œìŠ¤í…œ

ì£¼ìš” ê¸°ëŠ¥:
1. ë¡œê·¸ íŒŒì¼ í¬ê¸° ëª¨ë‹ˆí„°ë§
2. ìë™ ë¡œê·¸ ë¡œí…Œì´ì…˜ (í¬ê¸°/ë‚ ì§œ ê¸°ì¤€)
3. ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ìë™ ì‚­ì œ
4. GitHub ë¦¬í¬ì§€í† ë¦¬ ìµœì í™”
5. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
"""

import os
import sys
import shutil
import gzip
import logging
import schedule
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any
import json
import subprocess
import threading

# ë¡œê¹… ì„¤ì • (ìì²´ ë¡œê·¸ëŠ” ìµœì†Œí™”)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('log_cleanup.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class LogCleanupManager:
    """ë¡œê·¸ íŒŒì¼ ìë™ ê´€ë¦¬ì"""
    
    def __init__(self, config_file='log_cleanup_config.json'):
        self.config_file = config_file
        self.config = self.load_config()
        self.setup_logging()
        
    def load_config(self) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ ë˜ëŠ” ê¸°ë³¸ê°’ ìƒì„±"""
        default_config = {
            "log_directories": [
                ".",
                "logs/",
                "semiauto/",
                "autoinfo/core/",
                "autoinfo/webhook/",
                "kakao/"
            ],
            "log_patterns": [
                "*.log",
                "debug_*.html",
                "*.debug",
                "*.tmp"
            ],
            "max_file_size_mb": 10,  # 10MB ì´ìƒ íŒŒì¼ ì••ì¶•
            "max_age_days": 7,       # 7ì¼ ì´ìƒ íŒŒì¼ ì‚­ì œ
            "keep_compressed_days": 30,  # ì••ì¶• íŒŒì¼ 30ì¼ ë³´ê´€
            "exclude_files": [
                "log_cleanup.log",
                "requirements.txt",
                "README.md"
            ],
            "github_cleanup": {
                "enabled": True,
                "auto_commit": True,
                "commit_threshold_mb": 5  # 5MB ì´ìƒ ì •ë¦¬ì‹œ ìë™ ì»¤ë°‹
            },
            "monitoring": {
                "check_interval_minutes": 73,  # 73ë¶„ë§ˆë‹¤ ì²´í¬ (ë©”ì‹œì§€ ì‹œê°„ íšŒí”¼)
                "alert_threshold_mb": 50,      # 50MB ì´ìƒì‹œ ì•Œë¦¼
                "max_total_log_size_mb": 100   # ì „ì²´ ë¡œê·¸ 100MB ì œí•œ
            }
        }
        
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # ê¸°ë³¸ê°’ê³¼ ë³‘í•©
                    for key, value in default_config.items():
                        if key not in config:
                            config[key] = value
                    return config
            except Exception as e:
                logger.error(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
        
        # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±
        self.save_config(default_config)
        return default_config
    
    def save_config(self, config: Dict[str, Any]):
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"âŒ ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì • ìµœì í™”"""
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ë“¤ì˜ ë¡œê·¸ ë ˆë²¨ ì¡°ì •
        for handler in logging.root.handlers:
            if isinstance(handler, logging.FileHandler):
                # ë¡œê·¸ íŒŒì¼ í¬ê¸° ì œí•œ
                handler.setLevel(logging.WARNING)  # WARNING ì´ìƒë§Œ íŒŒì¼ì— ê¸°ë¡
    
    def find_log_files(self) -> List[Path]:
        """ë¡œê·¸ íŒŒì¼ ì°¾ê¸°"""
        log_files = []
        
        for directory in self.config['log_directories']:
            dir_path = Path(directory)
            if not dir_path.exists():
                continue
                
            for pattern in self.config['log_patterns']:
                for file_path in dir_path.glob(pattern):
                    if file_path.is_file() and file_path.name not in self.config['exclude_files']:
                        log_files.append(file_path)
        
        return log_files
    
    def get_file_size_mb(self, file_path: Path) -> float:
        """íŒŒì¼ í¬ê¸° MB ë‹¨ìœ„ë¡œ ë°˜í™˜"""
        try:
            return file_path.stat().st_size / (1024 * 1024)
        except:
            return 0
    
    def get_file_age_days(self, file_path: Path) -> int:
        """íŒŒì¼ ìƒì„±ì¼ë¡œë¶€í„° ê²½ê³¼ ì¼ìˆ˜"""
        try:
            file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
            return (datetime.now() - file_time).days
        except:
            return 0
    
    def compress_log_file(self, file_path: Path) -> bool:
        """ë¡œê·¸ íŒŒì¼ ì••ì¶•"""
        try:
            compressed_path = file_path.with_suffix(file_path.suffix + '.gz')
            
            with open(file_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            # ì›ë³¸ íŒŒì¼ ì‚­ì œ
            file_path.unlink()
            
            logger.info(f"ğŸ—œï¸ ì••ì¶• ì™„ë£Œ: {file_path.name} â†’ {compressed_path.name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì••ì¶• ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def delete_old_file(self, file_path: Path) -> bool:
        """ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ"""
        try:
            file_path.unlink()
            logger.info(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ: {file_path.name}")
            return True
        except Exception as e:
            logger.error(f"âŒ ì‚­ì œ ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def cleanup_logs(self) -> Dict[str, Any]:
        """ë¡œê·¸ íŒŒì¼ ì •ë¦¬ ì‹¤í–‰"""
        logger.info("ğŸ§¹ ë¡œê·¸ íŒŒì¼ ì •ë¦¬ ì‹œì‘...")
        
        log_files = self.find_log_files()
        stats = {
            'total_files': len(log_files),
            'compressed_files': 0,
            'deleted_files': 0,
            'freed_space_mb': 0,
            'errors': 0
        }
        
        for file_path in log_files:
            try:
                file_size_mb = self.get_file_size_mb(file_path)
                file_age_days = self.get_file_age_days(file_path)
                
                # ì••ì¶•ëœ íŒŒì¼ì€ ë” ì˜¤ë˜ ë³´ê´€ í›„ ì‚­ì œ
                if file_path.suffix == '.gz':
                    if file_age_days > self.config['keep_compressed_days']:
                        if self.delete_old_file(file_path):
                            stats['deleted_files'] += 1
                            stats['freed_space_mb'] += file_size_mb
                    continue
                
                # ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ
                if file_age_days > self.config['max_age_days']:
                    if self.delete_old_file(file_path):
                        stats['deleted_files'] += 1
                        stats['freed_space_mb'] += file_size_mb
                
                # í° íŒŒì¼ ì••ì¶•
                elif file_size_mb > self.config['max_file_size_mb']:
                    if self.compress_log_file(file_path):
                        stats['compressed_files'] += 1
                        # ì••ì¶•ìœ¼ë¡œ ì ˆì•½ëœ ê³µê°„ ì¶”ì • (ì•½ 70% ì••ì¶•ë¥ )
                        stats['freed_space_mb'] += file_size_mb * 0.7
                        
            except Exception as e:
                logger.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {file_path}: {e}")
                stats['errors'] += 1
        
        logger.info(f"âœ… ë¡œê·¸ ì •ë¦¬ ì™„ë£Œ: ì••ì¶• {stats['compressed_files']}ê°œ, ì‚­ì œ {stats['deleted_files']}ê°œ, ì ˆì•½ {stats['freed_space_mb']:.1f}MB")
        return stats
    
    def monitor_disk_usage(self) -> Dict[str, Any]:
        """ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
        try:
            total_log_size = 0
            log_files = self.find_log_files()
            
            for file_path in log_files:
                total_log_size += self.get_file_size_mb(file_path)
            
            # ì „ì²´ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
            disk_usage = shutil.disk_usage('.')
            free_space_gb = disk_usage.free / (1024**3)
            
            return {
                'total_log_size_mb': total_log_size,
                'free_space_gb': free_space_gb,
                'log_files_count': len(log_files),
                'alert_needed': total_log_size > self.config['monitoring']['alert_threshold_mb']
            }
            
        except Exception as e:
            logger.error(f"âŒ ë””ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def github_cleanup(self) -> bool:
        """GitHub ë¦¬í¬ì§€í† ë¦¬ ì •ë¦¬"""
        if not self.config['github_cleanup']['enabled']:
            return False
        
        try:
            # Git ìƒíƒœ í™•ì¸
            result = subprocess.run(['git', 'status', '--porcelain'], 
                                  capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.warning("âš ï¸ Git ë¦¬í¬ì§€í† ë¦¬ê°€ ì•„ë‹ˆê±°ë‚˜ Gitì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                return False
            
            # ë³€ê²½ëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if result.stdout.strip():
                logger.info("ğŸ“ Gitì— ë³€ê²½ì‚¬í•­ ê°ì§€ë¨")
                
                # ìë™ ì»¤ë°‹ì´ í™œì„±í™”ëœ ê²½ìš°
                if self.config['github_cleanup']['auto_commit']:
                    try:
                        # .gitignore í™•ì¸ ë° ì¶”ê°€
                        subprocess.run(['git', 'add', '.gitignore'], check=True)
                        
                        # ë¡œê·¸ íŒŒì¼ë“¤ì´ ì‹¤ìˆ˜ë¡œ ì¶”ê°€ë˜ì§€ ì•Šë„ë¡ ì œê±°
                        log_patterns = ['*.log', '*.debug', 'debug_*.html']
                        for pattern in log_patterns:
                            subprocess.run(['git', 'rm', '--cached', pattern], 
                                         capture_output=True)
                        
                        # ì»¤ë°‹
                        commit_message = f"ğŸ§¹ ìë™ ë¡œê·¸ ì •ë¦¬ - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                        subprocess.run(['git', 'commit', '-m', commit_message], 
                                     check=True)
                        
                        logger.info("âœ… ìë™ ì»¤ë°‹ ì™„ë£Œ")
                        return True
                        
                    except subprocess.CalledProcessError as e:
                        logger.error(f"âŒ ìë™ ì»¤ë°‹ ì‹¤íŒ¨: {e}")
                        return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ GitHub ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def generate_report(self) -> str:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            disk_info = self.monitor_disk_usage()
            log_files = self.find_log_files()
            
            report = f"""ğŸ“Š ë¡œê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬í¬íŠ¸
            
ğŸ• ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“ ë¡œê·¸ íŒŒì¼ í˜„í™©:
â€¢ ì´ íŒŒì¼ ìˆ˜: {len(log_files)}ê°œ
â€¢ ì´ í¬ê¸°: {disk_info.get('total_log_size_mb', 0):.1f}MB
â€¢ ì—¬ìœ  ê³µê°„: {disk_info.get('free_space_gb', 0):.1f}GB

âš™ï¸ ì„¤ì •:
â€¢ ìµœëŒ€ íŒŒì¼ í¬ê¸°: {self.config['max_file_size_mb']}MB
â€¢ ë³´ê´€ ê¸°ê°„: {self.config['max_age_days']}ì¼
â€¢ ì••ì¶• íŒŒì¼ ë³´ê´€: {self.config['keep_compressed_days']}ì¼

ğŸ¯ ë‹¤ìŒ ì •ë¦¬ ì˜ˆì •: {datetime.now() + timedelta(minutes=self.config['monitoring']['check_interval_minutes'])}
"""
            
            if disk_info.get('alert_needed'):
                report += f"\nâš ï¸ ê²½ê³ : ë¡œê·¸ íŒŒì¼ í¬ê¸°ê°€ {self.config['monitoring']['alert_threshold_mb']}MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!"
            
            return report
            
        except Exception as e:
            return f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}"
    
    def start_monitoring(self):
        """ìë™ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        logger.info("ğŸš€ ë¡œê·¸ ìë™ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‹œì‘")
        
        # ìŠ¤ì¼€ì¤„ ì„¤ì •
        interval = self.config['monitoring']['check_interval_minutes']
        schedule.every(interval).minutes.do(self.cleanup_logs)
        
        # ë§¤ì¼ ì˜¤ì „ 7ì‹œ30ë¶„ì— GitHub ì •ë¦¬ (ë©”ì‹œì§€ ì‹œê°„ ì™„ì „ íšŒí”¼)
        schedule.every().day.at("07:30").do(self.github_cleanup)
        
        # ë§¤ì£¼ ì¼ìš”ì¼ ì˜¤ì „ 7ì‹œì— ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„± (ë©”ì‹œì§€ ì‹œê°„ ì™„ì „ íšŒí”¼)
        schedule.every().sunday.at("07:00").do(self.generate_weekly_report)
        
        logger.info(f"â° ìŠ¤ì¼€ì¤„ ì„¤ì • ì™„ë£Œ: {interval}ë¶„ë§ˆë‹¤ ì •ë¦¬, ë§¤ì¼ 07:30 GitHub ì •ë¦¬")
        
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
        except KeyboardInterrupt:
            logger.info("â¹ï¸ ë¡œê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œ ì¢…ë£Œ")
    
    def generate_weekly_report(self):
        """ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = self.generate_report()
        
        # ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        report_file = f"log_report_{datetime.now().strftime('%Y%m%d')}.txt"
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"ğŸ“‹ ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        except Exception as e:
            logger.error(f"âŒ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def smart_compress_logs(self):
        """ìŠ¤ë§ˆíŠ¸ ë¡œê·¸ ì••ì¶• (ë‚´ìš© ê¸°ë°˜)"""
        print("\nğŸ—œï¸ ìŠ¤ë§ˆíŠ¸ ë¡œê·¸ ì••ì¶• ì¤‘...")
        
        compressed_count = 0
        total_saved = 0
        
        for log_file in self.logs_dir.rglob('*.log'):
            if log_file.stat().st_size > 5 * 1024 * 1024:  # 5MB ì´ìƒ
                try:
                    # ì¤‘ë³µ ë¼ì¸ ì œê±° í›„ ì••ì¶•
                    with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                        lines = f.readlines()
                    
                    # ì¤‘ë³µ ë¼ì¸ ì œê±° (ì—°ì†ëœ ë™ì¼í•œ ë¼ì¸)
                    unique_lines = []
                    prev_line = None
                    duplicate_count = 0
                    
                    for line in lines:
                        if line == prev_line:
                            duplicate_count += 1
                        else:
                            if duplicate_count > 0:
                                unique_lines.append(f"... (ìœ„ ë¼ì¸ì´ {duplicate_count}íšŒ ë°˜ë³µë¨)\n")
                                duplicate_count = 0
                            unique_lines.append(line)
                            prev_line = line
                    
                    # ì„ì‹œ íŒŒì¼ì— ì •ë¦¬ëœ ë‚´ìš© ì €ì¥
                    temp_file = log_file.with_suffix('.tmp')
                    with open(temp_file, 'w', encoding='utf-8') as f:
                        f.writelines(unique_lines)
                    
                    original_size = log_file.stat().st_size
                    temp_size = temp_file.stat().st_size
                    
                    # 20% ì´ìƒ ì ˆì•½ë˜ë©´ ì••ì¶•
                    if temp_size < original_size * 0.8:
                        # gzip ì••ì¶•
                        import gzip
                        with open(temp_file, 'rb') as f_in:
                            with gzip.open(log_file.with_suffix('.log.gz'), 'wb') as f_out:
                                f_out.writelines(f_in)
                        
                        # ì›ë³¸ íŒŒì¼ ì‚­ì œ
                        log_file.unlink()
                        temp_file.unlink()
                        
                        compressed_size = log_file.with_suffix('.log.gz').stat().st_size
                        saved = original_size - compressed_size
                        total_saved += saved
                        compressed_count += 1
                        
                        print(f"   ğŸ“¦ {log_file.name}: {self._format_size(saved)} ì ˆì•½")
                    else:
                        temp_file.unlink()
                        
                except Exception as e:
                    print(f"âš ï¸ {log_file.name} ì••ì¶• ì¤‘ ì˜¤ë¥˜: {e}")
        
        if compressed_count > 0:
            print(f"âœ… {compressed_count}ê°œ íŒŒì¼ ìŠ¤ë§ˆíŠ¸ ì••ì¶• ì™„ë£Œ")
            print(f"ğŸ’¾ ì´ ì ˆì•½ ê³µê°„: {self._format_size(total_saved)}")
        else:
            print("âœ… ì••ì¶•ì´ í•„ìš”í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
    
    def optimize_git_history(self):
        """Git íˆìŠ¤í† ë¦¬ ìµœì í™”"""
        print("\nğŸ”„ Git íˆìŠ¤í† ë¦¬ ìµœì í™” ì¤‘...")
        
        try:
            # Git ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            subprocess.run(['git', 'gc', '--aggressive', '--prune=now'], 
                         capture_output=True, text=True, check=True)
            
            # ë¦¬íŒ© ìµœì í™”
            subprocess.run(['git', 'repack', '-ad'], 
                         capture_output=True, text=True, check=True)
            
            print("âœ… Git íˆìŠ¤í† ë¦¬ ìµœì í™” ì™„ë£Œ")
            
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸ Git ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
    
    def analyze_repository_health(self):
        """ë¦¬í¬ì§€í† ë¦¬ ê±´ê°•ë„ ë¶„ì„"""
        print("\nğŸ“Š ë¦¬í¬ì§€í† ë¦¬ ê±´ê°•ë„ ë¶„ì„ ì¤‘...")
        
        health_score = 100
        issues = []
        
        # 1. ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²´í¬
        large_files = []
        for file_path in Path('.').rglob('*'):
            if file_path.is_file() and file_path.stat().st_size > 10 * 1024 * 1024:  # 10MB
                large_files.append((file_path, file_path.stat().st_size))
        
        if large_files:
            health_score -= min(20, len(large_files) * 5)
            issues.append(f"ğŸ”´ ëŒ€ìš©ëŸ‰ íŒŒì¼ {len(large_files)}ê°œ ë°œê²¬")
            for file_path, size in large_files[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                issues.append(f"   ğŸ“„ {file_path}: {self._format_size(size)}")
        
        # 2. ë¡œê·¸ íŒŒì¼ ì²´í¬
        log_count = len(list(Path('.').rglob('*.log')))
        if log_count > 10:
            health_score -= min(15, log_count - 10)
            issues.append(f"ğŸŸ¡ ë¡œê·¸ íŒŒì¼ {log_count}ê°œ (ê¶Œì¥: 10ê°œ ì´í•˜)")
        
        # 3. ì˜ì¡´ì„± íŒŒì¼ ì²´í¬
        req_files = list(Path('.').rglob('requirements*.txt'))
        if len(req_files) > 2:
            health_score -= 10
            issues.append(f"ğŸŸ¡ requirements íŒŒì¼ {len(req_files)}ê°œ (ê¶Œì¥: 1-2ê°œ)")
        
        # 4. README íŒŒì¼ ì²´í¬
        readme_files = list(Path('.').rglob('README*.md'))
        if len(readme_files) > 3:
            health_score -= 5
            issues.append(f"ğŸŸ¡ README íŒŒì¼ {len(readme_files)}ê°œ (ê¶Œì¥: 1-3ê°œ)")
        
        # ê±´ê°•ë„ ë“±ê¸‰ ê²°ì •
        if health_score >= 90:
            grade = "ğŸŸ¢ ìš°ìˆ˜"
        elif health_score >= 70:
            grade = "ğŸŸ¡ ì–‘í˜¸"
        elif health_score >= 50:
            grade = "ğŸŸ  ë³´í†µ"
        else:
            grade = "ğŸ”´ ê°œì„  í•„ìš”"
        
        print(f"ğŸ“ˆ ë¦¬í¬ì§€í† ë¦¬ ê±´ê°•ë„: {health_score}/100 ({grade})")
        
        if issues:
            print("\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œì :")
            for issue in issues:
                print(f"   {issue}")
        else:
            print("âœ… ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
        return health_score, issues

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ§¹ ë¡œê·¸ íŒŒì¼ ìë™ ê´€ë¦¬ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        manager = LogCleanupManager()
        
        if command == 'cleanup':
            # ì¦‰ì‹œ ì •ë¦¬ ì‹¤í–‰
            stats = manager.cleanup_logs()
            print(f"âœ… ì •ë¦¬ ì™„ë£Œ: {stats}")
            
        elif command == 'report':
            # ìƒíƒœ ë¦¬í¬íŠ¸ ì¶œë ¥
            report = manager.generate_report()
            print(report)
            
        elif command == 'monitor':
            # ëª¨ë‹ˆí„°ë§ ì‹œì‘
            manager.start_monitoring()
            
        elif command == 'github':
            # GitHub ì •ë¦¬
            success = manager.github_cleanup()
            print(f"GitHub ì •ë¦¬: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
            
        elif command == 'smart_compress':
            # ìŠ¤ë§ˆíŠ¸ ë¡œê·¸ ì••ì¶•
            manager.smart_compress_logs()
            
        elif command == 'optimize_git':
            # Git íˆìŠ¤í† ë¦¬ ìµœì í™”
            manager.optimize_git_history()
            
        elif command == 'analyze_repo':
            # ë¦¬í¬ì§€í† ë¦¬ ê±´ê°•ë„ ë¶„ì„
            health_score, issues = manager.analyze_repository_health()
            print(f"ë¦¬í¬ì§€í† ë¦¬ ê±´ê°•ë„: {health_score}/100 ({'ğŸŸ¢ ìš°ìˆ˜' if health_score >= 90 else 'ğŸŸ¡ ì–‘í˜¸' if health_score >= 70 else 'ğŸŸ  ë³´í†µ' if health_score >= 50 else 'ğŸ”´ ê°œì„  í•„ìš”'})")
            
            if issues:
                print("\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œì :")
                for issue in issues:
                    print(f"   {issue}")
            else:
                print("âœ… ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            
        else:
            print("ì‚¬ìš©ë²•: python log_cleanup_system.py [cleanup|report|monitor|github|smart_compress|optimize_git|analyze_repo]")
    
    else:
        # ê¸°ë³¸: ì¦‰ì‹œ ì •ë¦¬ í›„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        manager = LogCleanupManager()
        manager.cleanup_logs()
        manager.start_monitoring()

if __name__ == "__main__":
    main() 