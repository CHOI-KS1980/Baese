"""
ğŸš€ Auto Finance ë©”ì¸ ì‹¤í–‰ íŒŒì¼
ê³ ë„í™”ëœ ì£¼ì‹ ë‰´ìŠ¤ ìë™í™” ì‹œìŠ¤í…œ
"""

import asyncio
import json
import os
import time
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

# í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸
from auto_finance.core.news_crawler import NewsCrawler
from auto_finance.core.fact_checker import FactChecker
from auto_finance.core.financial_data import FinancialDataCollector
from auto_finance.core.content_generator import ContentGenerator, ContentRequest
from auto_finance.core.upload_manager import UploadManager, UploadRequest
from auto_finance.core.notification_system import NotificationSystem, NotificationMessage

# ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from auto_finance.utils.logger import setup_logger
from auto_finance.utils.error_handler import ErrorHandler
from auto_finance.utils.cache_manager import cache_manager
from auto_finance.utils.data_processor import data_processor
from auto_finance.utils.file_manager import file_manager

# ì„¤ì • ì„í¬íŠ¸
from auto_finance.config.settings import (
    NEWS_SOURCES, AI_CONFIG, FINANCIAL_CONFIG, 
    CONTENT_CONFIG, UPLOAD_CONFIG, NOTIFICATION_CONFIG
)

logger = setup_logger(__name__)

class AutoFinanceSystem:
    """Auto Finance ìë™í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.error_handler = ErrorHandler()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_running = False
        self.start_time = None
        
        # ì‹¤í–‰ í†µê³„
        self.execution_stats = {
            'total_executions': 0,
            'successful_executions': 0,
            'failed_executions': 0,
            'total_processing_time': 0.0,
            'last_execution': None,
            'components': {}
        }
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.crawled_articles = []
        self.fact_check_results = []
        self.generated_contents = []
        self.upload_results = []
        
        logger.info("ğŸš€ Auto Finance ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def run_full_pipeline(self) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        start_time = datetime.now()
        self.is_running = True
        
        logger.info("ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘")
        
        try:
            # 1ë‹¨ê³„: ë‰´ìŠ¤ í¬ë¡¤ë§
            logger.info("ğŸ“° 1ë‹¨ê³„: ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘")
            articles = await self._run_crawler()
            self.crawled_articles = articles
            
            # 2ë‹¨ê³„: AI íŒ©íŠ¸ ì²´í¬
            logger.info("ğŸ” 2ë‹¨ê³„: AI íŒ©íŠ¸ ì²´í¬ ì‹œì‘")
            fact_check_results = await self._run_fact_checker(articles)
            self.fact_check_results = fact_check_results
            
            # 3ë‹¨ê³„: ê¸ˆìœµ ë°ì´í„° ìˆ˜ì§‘
            logger.info("ğŸ“ˆ 3ë‹¨ê³„: ê¸ˆìœµ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            financial_data = await self._run_financial_collector()
            
            # 4ë‹¨ê³„: ì½˜í…ì¸  ìƒì„±
            logger.info("âœï¸ 4ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì‹œì‘")
            contents = await self._run_content_generator(articles, fact_check_results)
            self.generated_contents = contents
            
            # 5ë‹¨ê³„: ì—…ë¡œë“œ
            logger.info("ğŸ“¤ 5ë‹¨ê³„: ì—…ë¡œë“œ ì‹œì‘")
            upload_results = await self._run_upload_manager(contents)
            self.upload_results = upload_results
            
            # 6ë‹¨ê³„: ì•Œë¦¼ ì „ì†¡
            logger.info("ğŸ”” 6ë‹¨ê³„: ì•Œë¦¼ ì „ì†¡ ì‹œì‘")
            notification_results = await self._run_notification_system()
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_execution_stats(True, processing_time)
            
            # ê²°ê³¼ ìš”ì•½
            summary = self._generate_execution_summary(
                articles, fact_check_results, contents, upload_results, processing_time
            )
            
            logger.info(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {processing_time:.2f}ì´ˆ")
            return summary
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_execution_stats(False, processing_time)
            self.error_handler.handle_error(e, "ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")
            logger.error(f"âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
        
        finally:
            self.is_running = False
    
    async def _run_crawler(self) -> List[Dict[str, Any]]:
        """ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹¤í–‰"""
        try:
            async with NewsCrawler() as crawler:
                articles = await crawler.crawl_all_sources()
                
                # í†µê³„ ì €ì¥
                crawler.save_statistics()
                
                # ì»´í¬ë„ŒíŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
                self.execution_stats['components']['crawler'] = {
                    'articles_collected': len(articles),
                    'processing_time': crawler.stats.get('processing_time', 0),
                    'success_rate': len(articles) / len(NEWS_SOURCES) * 100 if NEWS_SOURCES else 0
                }
                
                logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(articles)}ê°œ ê¸°ì‚¬")
                return articles
                
        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _run_fact_checker(self, articles: List[Dict[str, Any]]) -> List[Any]:
        """íŒ©íŠ¸ ì²´ì»¤ ì‹¤í–‰"""
        try:
            if not articles:
                logger.warning("âš ï¸ íŒ©íŠ¸ ì²´í¬í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ìƒìœ„ 10ê°œ ê¸°ì‚¬ë§Œ íŒ©íŠ¸ ì²´í¬ (API ë¹„ìš© ì ˆì•½)
            top_articles = articles[:10]
            
            async with FactChecker() as fact_checker:
                results = await fact_checker.check_multiple_articles(top_articles)
                
                # ê²°ê³¼ ì €ì¥
                fact_checker.save_results(results)
                
                # ì»´í¬ë„ŒíŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
                self.execution_stats['components']['fact_checker'] = {
                    'articles_checked': len(results),
                    'average_score': fact_checker.stats.get('average_score', 0),
                    'success_rate': len(results) / len(top_articles) * 100 if top_articles else 0
                }
                
                logger.info(f"âœ… íŒ©íŠ¸ ì²´í¬ ì™„ë£Œ: {len(results)}ê°œ ê¸°ì‚¬")
                return results
                
        except Exception as e:
            logger.error(f"âŒ íŒ©íŠ¸ ì²´ì»¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _run_financial_collector(self) -> Dict[str, Any]:
        """ê¸ˆìœµ ë°ì´í„° ìˆ˜ì§‘ê¸° ì‹¤í–‰"""
        try:
            async with FinancialDataCollector() as collector:
                # ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘
                stocks = await collector.collect_all_stock_data()
                
                # ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
                indices = await collector.collect_all_index_data()
                
                # ë°ì´í„° ì €ì¥
                collector.save_data()
                
                # ì»´í¬ë„ŒíŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
                self.execution_stats['components']['financial_collector'] = {
                    'stocks_collected': len(stocks),
                    'indices_collected': len(indices),
                    'processing_time': collector.stats.get('processing_time', 0)
                }
                
                logger.info(f"âœ… ê¸ˆìœµ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(stocks)}ê°œ ì¢…ëª©, {len(indices)}ê°œ ì§€ìˆ˜")
                return {'stocks': stocks, 'indices': indices}
                
        except Exception as e:
            logger.error(f"âŒ ê¸ˆìœµ ë°ì´í„° ìˆ˜ì§‘ê¸° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {}
    
    async def _run_content_generator(self, articles: List[Dict[str, Any]], 
                                   fact_check_results: List[Any]) -> List[Any]:
        """ì½˜í…ì¸  ìƒì„±ê¸° ì‹¤í–‰"""
        try:
            if not articles:
                logger.warning("âš ï¸ ìƒì„±í•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ìƒìœ„ 5ê°œ ê¸°ì‚¬ë¡œ ì½˜í…ì¸  ìƒì„±
            top_articles = articles[:5]
            
            async with ContentGenerator() as generator:
                requests = []
                
                for i, article in enumerate(top_articles):
                    request = ContentRequest(
                        title=article['title'],
                        content=article.get('content', article['title']),
                        keywords=article.get('keywords', []),
                        content_type="article",
                        target_length=800,
                        tone="professional"
                    )
                    requests.append(request)
                
                contents = await generator.generate_multiple_contents(requests)
                
                # ì½˜í…ì¸  ì €ì¥
                for content in contents:
                    generator.save_content(content)
                
                # ì»´í¬ë„ŒíŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
                self.execution_stats['components']['content_generator'] = {
                    'contents_generated': len(contents),
                    'total_words': sum(c.word_count for c in contents),
                    'average_seo_score': sum(c.seo_score for c in contents) / len(contents) if contents else 0
                }
                
                logger.info(f"âœ… ì½˜í…ì¸  ìƒì„± ì™„ë£Œ: {len(contents)}ê°œ")
                return contents
                
        except Exception as e:
            logger.error(f"âŒ ì½˜í…ì¸  ìƒì„±ê¸° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _run_upload_manager(self, contents: List[Any]) -> List[Any]:
        """ì—…ë¡œë“œ ê´€ë¦¬ì ì‹¤í–‰"""
        try:
            if not contents:
                logger.warning("âš ï¸ ì—…ë¡œë“œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            async with UploadManager() as upload_manager:
                requests = []
                
                for content in contents:
                    # íŒŒì¼ ê²½ë¡œ ìƒì„±
                    file_path = f"data/generated/{content.title.replace(' ', '_')[:50]}.md"
                    
                    request = UploadRequest(
                        content_id=f"content_{hash(content.title)}",
                        title=content.title,
                        content=content.content,
                        file_path=file_path,
                        platform="tistory",  # ê¸°ë³¸ í”Œë«í¼
                        tags=content.keywords,
                        category="ì£¼ì‹ë‰´ìŠ¤"
                    )
                    requests.append(request)
                
                results = await upload_manager.upload_multiple_contents(requests)
                
                # ê²°ê³¼ ì €ì¥
                upload_manager.save_results(results)
                
                # ì»´í¬ë„ŒíŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
                self.execution_stats['components']['upload_manager'] = {
                    'uploads_attempted': len(results),
                    'successful_uploads': len([r for r in results if r.success]),
                    'success_rate': len([r for r in results if r.success]) / len(results) * 100 if results else 0
                }
                
                logger.info(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {len([r for r in results if r.success])}ê°œ ì„±ê³µ")
                return results
                
        except Exception as e:
            logger.error(f"âŒ ì—…ë¡œë“œ ê´€ë¦¬ì ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _run_notification_system(self) -> List[Any]:
        """ì•Œë¦¼ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        try:
            async with NotificationSystem() as notification_system:
                # ì‹¤í–‰ ì™„ë£Œ ì•Œë¦¼
                message = NotificationMessage(
                    title="Auto Finance íŒŒì´í”„ë¼ì¸ ì™„ë£Œ",
                    content=f"ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ëœ ê¸°ì‚¬: {len(self.crawled_articles)}ê°œ",
                    priority="normal",
                    category="system",
                    channels=["slack"],
                    recipients=["#general"],
                    metadata={},
                    created_at=datetime.now().isoformat()
                )
                
                results = await notification_system.send_notification(message)
                
                # ì»´í¬ë„ŒíŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
                self.execution_stats['components']['notification_system'] = {
                    'notifications_sent': len(results),
                    'successful_notifications': len([r for r in results if r.success]),
                    'success_rate': len([r for r in results if r.success]) / len(results) * 100 if results else 0
                }
                
                logger.info(f"âœ… ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: {len([r for r in results if r.success])}ê°œ ì„±ê³µ")
                return results
                
        except Exception as e:
            logger.error(f"âŒ ì•Œë¦¼ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _update_execution_stats(self, success: bool, processing_time: float):
        """ì‹¤í–‰ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.execution_stats['total_executions'] += 1
        self.execution_stats['total_processing_time'] += processing_time
        
        if success:
            self.execution_stats['successful_executions'] += 1
        else:
            self.execution_stats['failed_executions'] += 1
        
        self.execution_stats['last_execution'] = datetime.now().isoformat()
    
    def _generate_execution_summary(self, articles: List[Dict[str, Any]], 
                                  fact_check_results: List[Any],
                                  contents: List[Any],
                                  upload_results: List[Any],
                                  processing_time: float) -> Dict[str, Any]:
        """ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        summary = {
            'execution_id': f"exec_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'timestamp': datetime.now().isoformat(),
            'processing_time': processing_time,
            'components': {
                'crawler': {
                    'articles_collected': len(articles),
                    'sources_processed': len(NEWS_SOURCES)
                },
                'fact_checker': {
                    'articles_checked': len(fact_check_results),
                    'verified_count': len([r for r in fact_check_results if r.verification_status == 'verified'])
                },
                'content_generator': {
                    'contents_generated': len(contents),
                    'total_words': sum(c.word_count for c in contents) if contents else 0
                },
                'upload_manager': {
                    'uploads_attempted': len(upload_results),
                    'successful_uploads': len([r for r in upload_results if r.success])
                }
            },
            'overall_stats': self.execution_stats,
            'error_summary': self.error_handler.get_statistics()
        }
        
        return summary
    
    def save_execution_summary(self, summary: Dict[str, Any], 
                             file_path: str = "data/execution_summary.json"):
        """ì‹¤í–‰ ìš”ì•½ ì €ì¥"""
        try:
            # ê¸°ì¡´ ìš”ì•½ ë¡œë“œ
            summaries = []
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    summaries = json.load(f)
            
            # ìƒˆ ìš”ì•½ ì¶”ê°€
            summaries.append(summary)
            
            # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            if len(summaries) > 100:
                summaries = summaries[-100:]
            
            # ì €ì¥
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(summaries, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ’¾ ì‹¤í–‰ ìš”ì•½ ì €ì¥: {file_path}")
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            'is_running': self.is_running,
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'execution_stats': self.execution_stats,
            'error_statistics': self.error_handler.get_statistics(),
            'cache_statistics': cache_manager.get_statistics(),
            'timestamp': datetime.now().isoformat()
        }

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ Auto Finance ì‹œìŠ¤í…œ ì‹œì‘")
    
    # ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    system = AutoFinanceSystem()
    
    try:
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        summary = await system.run_full_pipeline()
        
        # ì‹¤í–‰ ìš”ì•½ ì €ì¥
        system.save_execution_summary(summary)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ‰ Auto Finance íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("="*60)
        print(f"ğŸ“° ìˆ˜ì§‘ëœ ê¸°ì‚¬: {summary['components']['crawler']['articles_collected']}ê°œ")
        print(f"ğŸ” íŒ©íŠ¸ ì²´í¬: {summary['components']['fact_checker']['articles_checked']}ê°œ")
        print(f"âœï¸ ìƒì„±ëœ ì½˜í…ì¸ : {summary['components']['content_generator']['contents_generated']}ê°œ")
        print(f"ğŸ“¤ ì—…ë¡œë“œ ì„±ê³µ: {summary['components']['upload_manager']['successful_uploads']}ê°œ")
        print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {summary['processing_time']:.2f}ì´ˆ")
        print("="*60)
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
        status = system.get_system_status()
        print(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: {status['execution_stats']['successful_executions']}/{status['execution_stats']['total_executions']} ì„±ê³µ")
        
    except Exception as e:
        logger.error(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"\nâŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    finally:
        logger.info("ğŸ Auto Finance ì‹œìŠ¤í…œ ì¢…ë£Œ")

if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(main()) 